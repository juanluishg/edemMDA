{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ez1mc8B6Yw1Q",
    "outputId": "af093dc9-e370-4a4b-8b45-d7ca961e8a0b"
   },
   "outputs": [],
   "source": [
    "!pip install -q findspark==1.3.0\n",
    "!pip install py4j==0.10.9\n",
    "\n",
    "# For plotting\n",
    "!pip install folium\n",
    "!pip install plotly\n",
    "\n",
    "!pip install psycopg2\n",
    "!pip install pandas\n",
    "!pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pZAypTcIY0AH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop2.7\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "tO-Ce5QWY15-",
    "outputId": "f8e86059-0c64-4ff0-acde-b87ba2c8e663"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.add_packages([\"org.apache.spark:spark-sql-kafka-0-10_2.12:3.0.1\"])\n",
    "findspark.add_jars([\"/content/spark-3.0.1-bin-hadoop2.7/jars/kafka-clients-2.0.0.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/lz4-java-1.4.1-jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/scala-library-2.11.12.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/slf4j-api-1.7.25.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/snappy-java-1.1.7.1.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/spark-sql-kafka-0-10_2.11-2.4.5.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/spark-tags_2.11-2.4.5.jar\",\"/content/spark-3.0.1-bin-hadoop2.7/jars/unused-1.0.0.jar\"])\n",
    "findspark.init(\"/content/spark-3.0.1-bin-hadoop2.7\")# SPARK_HOME\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.ui.port\", \"4040\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "id": "C-PzsSkPY6fe",
    "outputId": "b63e6b9c-4726-4583-d30f-492d7f937f31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://jupyterPySpark:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f3e58e9c8b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-fCca8lkY9sf"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VZBYGRQSZxho",
    "outputId": "c87990f6-d906-41c2-e412-8d58742c0a4b"
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "import requests\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "QuKcu1GkZrRt"
   },
   "outputs": [],
   "source": [
    "def connect():\n",
    "    try:\n",
    "        connection = psycopg2.connect(user = \"postgres\",\n",
    "                                      password = \"Welcome01\",\n",
    "                                      host = \"104.154.145.52\",\n",
    "                                      port = \"5432\",\n",
    "                                      database = \"dataproject2\")\n",
    "       \n",
    "        cursor = connection.cursor()\n",
    "        return cursor\n",
    "        \n",
    "    except (Exception, psycopg2.Error) as error :\n",
    "        print (\"Error while connecting to PostgreSQL\", error)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LqWlXMg3Zm1H"
   },
   "outputs": [],
   "source": [
    "def algoritmo(text_person):\n",
    "    tg0 = time.time()\n",
    "    cursor = connect()\n",
    "    \n",
    "    playa = [\"Valencia\", \"Barcelona\", \"Ibiza\"]\n",
    "    ciudad = [\"Madrid\", \"Barcelona\", \"Valencia\", \"Sevilla\"]\n",
    "    naturaleza = [\"Oviedo\", \"Bilbao\"]\n",
    "    fiesta = [\"Ibiza\", \"Madrid\", \"Barcelona\"]\n",
    "    \n",
    "    scoring = {\"Madrid\": 0, \"Barcelona\": 0, \"Ibiza\": 0, \"Valencia\": 0, \"Sevilla\": 0, \"Oviedo\": 0, \"Bilbao\": 0}\n",
    "    \n",
    "    json_person = json.loads(text_person)\n",
    "    tweet_text = json_person['full_text']\n",
    "    tweet_person_id = json_person['id']\n",
    "    \n",
    "    split_text = tweet_text.split(\" \")\n",
    "    try:\n",
    "        name = split_text[3] + \" \" + split_text[4][:-1]\n",
    "        salary = split_text[8][:-1]\n",
    "        members = split_text[19]\n",
    "        beach = split_text[25][-3:-2]\n",
    "        city = split_text[26][-3:-2]\n",
    "        nature = split_text[27][-3:-2]\n",
    "        party = split_text[28][-2:-1]\n",
    "\n",
    "        t0 = time.time()\n",
    "        \n",
    "        for k in scoring:\n",
    "            try:\n",
    "                playa.index(k)\n",
    "                scoring[k] += int(beach)\n",
    "            except (Exception) as error :\n",
    "                print(\"Not present\", error)\n",
    "\n",
    "            try:\n",
    "                ciudad.index(k)\n",
    "                scoring[k] += int(city)\n",
    "            except (Exception) as error :\n",
    "                print(\"Not present\", error)\n",
    "\n",
    "            try:\n",
    "                naturaleza.index(k)\n",
    "                scoring[k] += int(nature)\n",
    "            except (Exception) as error :\n",
    "                print(\"Not present\", error)\n",
    "\n",
    "            try:\n",
    "                fiesta.index(k)\n",
    "                scoring[k] += int(party)\n",
    "            except (Exception) as error :\n",
    "                print(\"Not present\", error)\n",
    "\n",
    "        t1 = time.time()\n",
    "        print(\"Tiempo de scoring: \"+ str(t1-t0))\n",
    "        \n",
    "        t0 = time.time()\n",
    "        cursor.execute(\"SELECT * FROM casas WHERE cost <= \" + str((int(salary)/12)*0.2) + \" and (rooms = \"\n",
    "                       + str(members) + \" or rooms = \" + str(int(members)+1) + \") and c_counter <=4;\")\n",
    "        record = cursor.fetchall()\n",
    "\n",
    "        cursor.execute(\"SELECT COLUMN_NAME FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = N'casas'\")\n",
    "        columns_name = cursor.fetchall()\n",
    "        \n",
    "        t1 = time.time()\n",
    "        print(\"Tiempo de consulta a base de datos: \"+ str(t1-t0))\n",
    "\n",
    "        \"\"\"Convert array of arrays to single array\"\"\"\n",
    "\n",
    "        array_columns_name = np.array(columns_name)\n",
    "        array_columns_name = np.concatenate( array_columns_name, axis=0 )\n",
    "\n",
    "        print(array_columns_name)\n",
    "\n",
    "        \"\"\"Transform result of query to a pandas dataframe\"\"\"\n",
    "\n",
    "        df = pd.DataFrame(record, columns=array_columns_name)\n",
    "\n",
    "        #casas_coste = df[df.cost <= ((int(salary)/12)*0.2)]\n",
    "\n",
    "        #casas_hab = casas_coste.loc[(casas_coste.rooms == members) | ((casas_coste.rooms.astype(int)) == int(members)+1)]\n",
    "\n",
    "        #casas_libres = casas_hab.loc[casas_hab.c_counter <= 4]\n",
    "        mejor_casa = df\n",
    "        mejor_casa['score'] = mejor_casa['city_name'].map(scoring)\n",
    "        resultado = mejor_casa[mejor_casa.score == max(mejor_casa.score)]\n",
    "\n",
    "        consumer_key = \"ZHwb6JawdsgTUZreb4yZeb2tX\"\n",
    "        consumer_secret = \"2UoU6lEpNeTPM847paK6X6z6BVoUENhPq87rIIWcOycnNhGtpd\"\n",
    "        access_token = \"1346037018132930560-G3afFHkhsPiYlo1yFO3X4mTmdJhTOY\"\n",
    "        access_token_secret = \"jLjtkTK9VQVitacVhLj8QtSdb0mkOto4J9PDDSWR9x9Q0\"\n",
    "\n",
    "        images_url = {\"Madrid\": \"https://www.enforex.com/images/fichas/madrid/ciudad-madrid-2.jpg\", \n",
    "                  \"Barcelona\": \"https://www.alsa.es/documents/21643679/21664598/Barcelona.jpg\", \n",
    "                  \"Ibiza\": \"https://www.iagua.es/sites/default/files/styles/thumbnail-700x700/public/1155x510-ibiza1.jpg?itok=0SafgsGX\", \n",
    "                  \"Valencia\": \"https://static.lasprovincias.es/www/multimedia/202009/30/media/cortadas/valencia-turismo-tarjeta-kfHG-U1203216296067wG-624x385@Las%20Provincias.jpg\", \n",
    "                  \"Sevilla\": \"https://elcorreoweb.es/binrepository/plaza-espana-sevilla_20333351_20200107162131.jpg\", \n",
    "                  \"Oviedo\": \"https://www.iberia.com/ibcomv3/content/landings/OVD.jpg\", \n",
    "                  \"Bilbao\": \"https://www.leonardo-hotels.es/octopus/Upload/images/Pages/bilbao-1920x580.jpg\"}\n",
    "\n",
    "        # Configuración de acceso con las credenciales\n",
    "        auth = OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "        # Listos para hacer la conexión con el API\n",
    "        api = tweepy.API(auth)\n",
    "\n",
    "        t0 = time.time()\n",
    "        contador = 0\n",
    "        for _, i in resultado.iterrows():\n",
    "            # Ofrecer como maximo 2 casas a una misma persona\n",
    "            if contador >= 2:\n",
    "                break;    \n",
    "\n",
    "            tweet = \"Hi! \"+ name + \", your perfect house is placed in \" + i.city_name + \", with the code: \" + str(i.house_id)\n",
    "            tweet += \" https://twitter.com/dlpexercisepro1/status/\" + str(i.tweet_id)\n",
    "\n",
    "            t2 = time.time()\n",
    "            # Download the image\n",
    "            url = images_url.get(i.city_name)\n",
    "            filename = '/tmp/temp.jpg'\n",
    "            request = requests.get(url, stream=True)\n",
    "            if request.status_code == 200:\n",
    "                with open(filename, 'wb') as image:\n",
    "                    for chunk in request:\n",
    "                        image.write(chunk)\n",
    "            else:\n",
    "                return \"Unable to download image\"\n",
    "            \n",
    "            t3 = time.time()\n",
    "            print(\"Tiempo de descarga de imagen: \" +str(t3-t2))\n",
    "\n",
    "            # Publish Tweet with image\n",
    "            api.update_with_media(filename, status=tweet, in_reply_to_status_id = tweet_person_id, auto_populate_reply_metadata = True)\n",
    "\n",
    "            os.remove(filename)   \n",
    "            contador += 1\n",
    "\n",
    "            # Increment house counter\n",
    "            cursor.execute(\"UPDATE casas SET c_counter = c_counter + 1 WHERE tweet_id = \" + str(i.tweet_id))\n",
    "        t1 = time.time()\n",
    "        print(\"Tiempo de publicación: \"+ str(t1-t0))\n",
    "        tg1 = time.time()\n",
    "        print(\"Tiempo total: \"+ str(tg1-tg0))\n",
    "        return \"publicado\"\n",
    "    except (Exception) as error :\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-DEgf4WTZCZY",
    "outputId": "53196c6b-2706-4aed-8c47-80eec2c1e0c8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.StreamingQuery at 0x7f3e52014a00>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import from_json, col\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType\n",
    "\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .option(\"kafka.bootstrap.servers\", \"broker:29092\") \\\n",
    "    .option(\"subscribe\", \"este\") \\\n",
    "    .load()\n",
    "    \n",
    "#df.printSchema()  \n",
    "\n",
    "schema = StructType(\n",
    "    [\n",
    "     StructField('created_at', StringType(), True),\n",
    "     StructField('id', StringType(), True),\n",
    "     StructField('full_text', StringType(), True),\n",
    "     StructField('text', StringType(), True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
    "    .withColumn(\"value\", from_json(\"value\", schema)) \\\n",
    "    .select(col('key'), col(\"timestamp\"), col('value.*'))\n",
    "\n",
    "#df1 = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
    "#        .select(col('key'), col('timestamp'), col('value'))\n",
    "\n",
    "dataset.writeStream \\\n",
    "  .outputMode(\"update\") \\\n",
    "  .format(\"memory\") \\\n",
    "  .option(\"truncate\", \"false\") \\\n",
    "  .queryName(\"tweets\") \\\n",
    "  .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rrjaf3wdaBuP",
    "outputId": "edf90c4e-ebfe-48c0-e94d-cbb92bc5124a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|key |timestamp              |created_at                    |id                 |full_text                                                                                                                                                                 |text                                                                                                                                        |\n",
      "+----+-----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|null|2021-02-07 19:07:27.139|Sun Feb 07 17:47:40 +0000 2021|1358472511747424259|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my hobbies: Beach(5), City(2), Nature(7), Party(0)  #mdaedem|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my ho… https://t.co/wojkgqPnHy|\n",
      "|null|2021-02-07 19:05:08.086|Sun Feb 07 17:47:40 +0000 2021|1358472511747424259|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my hobbies: Beach(5), City(2), Nature(7), Party(0)  #mdaedem|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my ho… https://t.co/wojkgqPnHy|\n",
      "+----+-----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from tweets order by timestamp desc\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spark_algoritmo(f, sp_id):\n",
    "    return algoritmo(f.value.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark.udf.register(\"udf_algoritmo\", algoritmo) \n",
    "spark.udf.register(\"udf_spark_algoritmo\", spark_algoritmo) \n",
    "\n",
    "dataset1 = df.selectExpr(\"CAST(key AS STRING)\", \"CAST(value AS STRING)\", \"timestamp\") \\\n",
    "    .withColumn(\"value\", from_json(\"value\", schema)) \\\n",
    "    .select(col('key'), col(\"timestamp\"), col('value.*'))\n",
    "\n",
    "tweet_proc = dataset1.writeStream \\\n",
    "                .foreachBatch(spark_algoritmo) \\\n",
    "                .outputMode(\"update\") \\\n",
    "                .format(\"memory\") \\\n",
    "                .option(\"truncate\", \"false\") \\\n",
    "                .queryName(\"output1\") \\\n",
    "                .start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|key |timestamp             |created_at                    |id                 |full_text                                                                                                                                                                 |text                                                                                                                                        |\n",
      "+----+----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|null|2021-02-07 19:18:29.99|Sun Feb 07 17:47:40 +0000 2021|1358472511747424259|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my hobbies: Beach(5), City(2), Nature(7), Party(0)  #mdaedem|My name is Austin Huber, my salary is 65536€ yearly and I am 36 years old. My family are 4 members. These are my ho… https://t.co/wojkgqPnHy|\n",
      "+----+----------------------+------------------------------+-------------------+--------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from output1\").show(truncate = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Dataproject 2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
