{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDEM - GANs - 6. GANs condicionales - FashionMNIST.ipynb","provenance":[{"file_id":"1_gp6NLeFTSNo2gEI3VUDBhcz11SF_-ok","timestamp":1585719561858},{"file_id":"1AEhoe0H4X4Z2znZofXuXtq-jNzJI4Ef8","timestamp":1585124465139}],"collapsed_sections":[],"authorship_tag":"ABX9TyMOJfSWKYeyuAkSWDh2L57W"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"eyrjJP7MqpAN","colab_type":"text"},"source":["Vamos a ver un ejemplo de GANs condicionales con el dataset FashionMNIST\n"]},{"cell_type":"code","metadata":{"id":"8bCnkVIwrJz8","colab_type":"code","colab":{}},"source":["# importamos las librerías necesarias\n","import numpy as np\n","from tensorflow.keras.datasets.fashion_mnist import load_data\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Embedding, Concatenate, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n","import matplotlib.pyplot as plt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7y3jZ4gVrMAz","colab_type":"code","colab":{}},"source":["# definimos el discriminador: en este caso va a ser convolucional\n","def define_discriminator(in_shape=(28, 28, 1), n_classes=10):\n","    # En esta ocasión vamos a usar la API funcional de KERAS\n","\n","    # creamos la entrada de la información condicional\n","    in_label = Input(shape=(1,))\n","    emb = Embedding(n_classes, 50)(in_label)\n","    n_nodes = in_shape[0] * in_shape[1]\n","    mapping_cond_inf = Dense(n_nodes)(emb)\n","    mapping_cond_inf = Reshape((in_shape[0], in_shape[1], 1))(mapping_cond_inf)\n","\n","    # entrada de la imagen\n","    in_image = Input(shape=in_shape)\n","    # concatenamos la info condicional con la imagen\n","    merge = Concatenate()([in_image, mapping_cond_inf])\n","    # downsample\n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(merge)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    # downsample\n","    fe = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(fe)\n","    fe = LeakyReLU(alpha=0.2)(fe)\n","    fe = Flatten()(fe)\n","    fe = Dropout(0.4)(fe)\n","    out_layer = Dense(1, activation='sigmoid')(fe)\n","    # definimos y compilamos el modelo\n","    model = Model([in_image, in_label], out_layer)\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nucb657PrT_R","colab_type":"code","colab":{}},"source":["# definimos el generador\n","def define_generator(latent_dim, n_classes=10):\n","    # Aquí también vamos a utilizar la API funcional de Keras\n","    \n","    # creamos la entrada de la información condicional\n","    in_label = Input(shape=(1,))\n","    emb = Embedding(n_classes, 50)(in_label)\n","    n_nodes = 7 * 7\n","    mapping_cond_inf = Dense(n_nodes)(emb)\n","    mapping_cond_inf = Reshape((7, 7, 1))(mapping_cond_inf)\n","    \n","    # entrada del código latene\n","    in_lat = Input(shape=(latent_dim,))\n","    # vamos a mapear nuestro código latente a un espacio bidimensional de mayor\n","    # número de dimensiones para poder tratar con él con nuestra CNN\n","    n_nodes = 128 * 7 * 7\n","    gen = Dense(n_nodes)(in_lat)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    gen = Reshape((7, 7, 128))(gen)\n","    # concatenamos el código latente y la información\n","    merge = Concatenate()([gen, mapping_cond_inf])\n","    # aumentamos a 14x14\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(merge)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    # aumentamos a 28x28\n","    gen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(gen)\n","    gen = LeakyReLU(alpha=0.2)(gen)\n","    # salida del modelo (una imagen en escala de grises de 28x28)\n","    out_layer = Conv2D(1, (7,7), activation='tanh', padding='same')(gen)\n","    # definimos el modelo\n","    model = Model([in_lat, in_label], out_layer)\n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0CKU8au2sfY9","colab_type":"code","colab":{}},"source":["# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n","def define_gan(g_model, d_model):\n","    # Así que congelamos el discriminador:\n","    d_model.trainable = False\n","    # obtenemos las entradas del generador\n","    gen_noise, gen_label = g_model.input\n","    # obtenemos la salida del generador (la nueva imagen generada)\n","    gen_output = g_model.output\n","    # le introducimos la imagen generada y la clase que debería ser al discriminador\n","    gan_output = d_model([gen_output, gen_label])\n","    # definimos el modelo completo\n","    model = Model([gen_noise, gen_label], gan_output)\n","    # y compilamos el modelo\n","    opt = Adam(lr=0.0002, beta_1=0.5)\n","    model.compile(loss='binary_crossentropy', optimizer=opt) \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"acd2xBRrs1Sm","colab_type":"code","colab":{}},"source":["# definimos las funciones para cargar el MNIST\n","def load_real_samples():\n","    # cargamos el dataset - ESTA VEZ QUEREMOS LAS IMÁGENES Y LAS CLASES\n","    (trainX, trainY), (_, _) = load_data()\n","    # expandimos la dimensión del batch\n","    X = np.expand_dims(trainX, axis=-1)\n","    # convertimos a float32\n","    X = X.astype('float32')\n","    # escalamos entre -1 y 1\n","    X = (X - 127.5) / 127.5\n","    # devolvemos tanto las imágenes como las clases\n","    return [X, trainY]\n","\n","# nos creamos una función que nos devuelva n_samples del dataset (imagen, clase) \n","# y generamos las etiquetas de entrenamiento GAN: 1 \n","def generate_real_samples(dataset, n_samples):\n","    # separamos las imágenes de las etiquetas\n","    images, labels = dataset\n","    # seleccionamos n_samples muestras aleatoriamente\n","    ix = np.random.randint(0, images.shape[0], n_samples)\n","    # las cogemos junto a su correspondiente clase\n","    X, labels = images[ix], labels[ix]\n","    # generamos las etiquetas para entrenar la GAN (1)\n","    y = np.ones((n_samples, 1))\n","    return [X, labels], y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0o9oAmXgs61c","colab_type":"code","colab":{}},"source":["# generamos los vectores latentes que introduciremos al generador\n","def generate_latent_points(latent_dim, batch_size, n_classes=10):\n","    # generamos un vector de batch_size * latent_dim números aleatorios\n","    # latent_dim es la dimensión del vector latente\n","    # batch_size es el número de elementos por batch\n","    x_input = np.random.randn(latent_dim * batch_size)\n","    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n","    z_input = x_input.reshape(batch_size, latent_dim)\n","    # generamos clases aleatoriamente: la imagen producida por este código\n","    # latente y clase deberá ser una imagen realista que pertenezca a dicha\n","    # clase!\n","    labels = np.random.randint(0, n_classes, batch_size)\n","    return [z_input, labels]\n","\n","# creamos datos fake con el generador (dinero falsificado)\n","def generate_fake_samples(g_model, latent_dim, n_samples): \n","    # usamos la función anterior para generar los vectores latentes que \n","    # necesitamos para generar muestras fake acompañados de las clases \n","    # a las que queremos que pertenezcan las imágenes generadas\n","    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n","    # le introducimos los vectores latentes y las clases al generador para obtener\n","    # muestras similares a las reales\n","    images = g_model.predict([z_input, labels_input])\n","    # le asignamos la etiqueta 1 (porque utilizaremos esta función para\n","    # entrenar el G y en ese caso queremos \"engañar\" al D)\n","    y = np.zeros((n_samples, 1)) \n","    return [images, labels_input], y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ihC0sltV2URE","colab_type":"code","colab":{}},"source":["# función para guardar las imágenes generadas\n","def save_plot(examples, epoch, n=10, figsize=(20, 20)):\n","    examples = (examples * 127.5) + 127.5\n","    plt.figure(figsize=figsize)\n","    for i in range(n * n):\n","        plt.subplot(n, n, 1 + i)\n","        plt.axis('off')\n","        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n","    # guardamos las imágenes\n","    filename = 'generated_plot_e%03d.png' % (epoch+1)\n","    plt.savefig(filename)\n","    plt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vBkSW8WH2Zzz","colab":{}},"source":["# función para entrenar la GAN: el discriminador y el generador\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=256):\n","    bat_per_epo = int(dataset[0].shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # bucle para las epochs\n","    for epoch in range(n_epochs):\n","        # bucle para los batch\n","        for batch in range(bat_per_epo):\n","            \n","            # en esta ocasión vamos a separar las pérdidas del discriminador\n","            # cuando le metemos imágenes reales y cuando le metemos imágenes\n","            # fake para ver cómo lo hace con cada tipo\n","            # recordad que lo ideal es que llegue a un 50% de acc en cada uno\n","\n","            # preparamos los datos reales\n","            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","            # actualizamos el discriminador\n","            d_loss1, _ = d_model.train_on_batch([X_real, labels_real], y_real)\n","            \n","            # generamos datos falsos\n","            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            # actualizamos el discriminador\n","            d_loss2, _ = d_model.train_on_batch([X_fake, labels_fake], y_fake)\n","\t\t\t\n","            # preparamos los puntos en el espacio latente: serán la entrada al\n","            # modelo GAN con el que entrenaremos el generador\n","            [z_input, labels_input] = generate_latent_points(latent_dim, n_batch)\n","            \n","            # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n","            # para que piense que las muestras que le introducimos son reales, y\n","            # en caso de que diga que no son reales, aprovechamos la información\n","            # de sus gradientes para actualizar el G(z) para que la próxima vez\n","            # los datos generados por G(z) sean más plausibles (parecidos a los \n","            # reales)\n","            y_gan = np.ones((n_batch, 1))\n","            \n","            # como acabamos de ver, entrenamos el generador de forma que actualice\n","            # sus pesos usando los gradientes del discriminador\n","            # tened en cuenta que en este modelo (gan_model) el discriminador está\n","            # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n","            # a nuestro policía, lo que queremos es fabricar dinero más realista.\n","            g_loss = gan_model.train_on_batch([z_input, labels_input], y_gan)\n","\n","            # mostramos el progreso\n","            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % \n","                  (epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","        # evaluamos el desempeño del modelo cada 10 épocas\n","        if (epoch+1) % 10 == 0 or epoch == 0:\n","            # preparamos los datos reales\n","            [X_real, labels_real], y_real = generate_real_samples(dataset, half_batch)\n","            # evaluamos el discriminador con datos reales\n","            _, acc_real = d_model.evaluate([X_real, labels_real], y_real, verbose=0)\n","            # preparamos ejemplos fake\n","            [X_fake, labels_fake], y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n","            # evaluamos el discriminador con datos fake\n","            _, acc_fake = d_model.evaluate([X_fake, labels_fake], y_fake, verbose=0)\n","            # mostramos cómo de bueno es nuestro policía\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","            # guardamos las imágenes generadas\n","            save_plot(X_fake, epoch)\n","            # guardamos el generador para tenerlo disponible más tarde\n","            filename = 'cgan_generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LkIcUyas2Zz2","colab":{}},"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V9LXaAVb4Rri","colab_type":"code","colab":{}},"source":["ls -lah"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"D9kHiRJtwBDs","colab_type":"code","colab":{}},"source":["# montamos la unidad drive donde tenemos los datos en la carpeta drive/My Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tw1lSh5JwBc1","colab_type":"code","colab":{}},"source":["# los guardamos en nuestro drive para evitar tener que reejecutar cada vez\n","!mkdir drive/My\\ Drive/7_cond_dcgan_fashionmnist\n","!cp *gen* drive/My\\ Drive/7_cond_dcgan_fashionmnist/\n","!ls -lah drive/My\\ Drive/7_cond_dcgan_fashionmnist/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uQitNcy-Cjgn","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","plt.imshow(plt.imread('generated_plot_e001.png'))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Ez8QfGI4UjH","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","plt.imshow(plt.imread('generated_plot_e010.png'))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dixkDKlF4pXX","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","plt.imshow(plt.imread('generated_plot_e100.png'))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"l57oPvHkv6De","colab_type":"code","colab":{}},"source":["# vamos a generar imágenes de una determinada clase\n","from tensorflow.keras.models import load_model\n","\n","# cargamos el modelo\n","model = load_model('cgan_generator_model_100.h5')\n","# generate images\n","latent_points, labels = generate_latent_points(100, 100)\n","# specify labels\n","labels = np.asarray([x for _ in range(10) for x in range(10)])\n","# generate images\n","X  = model.predict([latent_points, labels])\n","# scale from [-1,1] to [0,1]\n","X = (X + 1) / 2.0\n","# plot the result\n","save_plot(X, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vvmbBfixwxgL","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 10))\n","plt.imshow(plt.imread('generated_plot_e101.png'))\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HATtkwaJxbF4","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}