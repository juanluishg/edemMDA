{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDEM - GANs - 5. Explorando el espacio latente - CelebA.ipynb","provenance":[{"file_id":"1AEhoe0H4X4Z2znZofXuXtq-jNzJI4Ef8","timestamp":1585588351003}],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyPXuf3Twv2i3X8mRyFvj/57"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"o7ZPd7FUC9c_","colab_type":"text"},"source":["Para montar vuestra unidad drive siempre que lo necesitéis:\n"]},{"cell_type":"code","metadata":{"id":"ajR7ndr9DEKH","colab_type":"code","colab":{}},"source":["# montamos la unidad drive donde tenemos los datos en la carpeta drive/My Drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kbEPr-6nCx_a","colab_type":"text"},"source":["# Preparamos los datos"]},{"cell_type":"code","metadata":{"id":"mA4_QI3aNSUo","colab_type":"code","colab":{}},"source":["# por compatibilidad, necesitamos TF 1.x\n","%tensorflow_version 1.x"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rHz3w-Rn9uMJ","colab_type":"code","colab":{}},"source":["# Descargad solo las imágenes del dataset CelebA (https://drive.google.com/open?id=0B7EVK8r0v71pZjFTYXZWM3FlRnM) y subidlo a FileBin.com\n","# Luego descargadlo y descomprimidlo\n","# !wget URL\n","# unzip img_align_celeba.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gpfCZ910MOXA","colab_type":"code","colab":{}},"source":["# también podéis hacerlo montando vuestra unidad tras haber guardado una copia del arhivo en ella\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xCX5kq-MYmg","colab_type":"code","colab":{}},"source":["# al haber montado la unidad en /content/drive, los archivos deberían estar disponibles ahí.\n","# también podéis utilizar el menú de la izquierda, haciendo click en la carpetita, para\n","# explorar vuestra estructura de archivos\n","!ls drive/My\\ Drive"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EBvbgHkQMinZ","colab_type":"code","colab":{}},"source":["# descomprimimos las imágenes\n","!unzip drive/My\\ Drive/img_align_celeba.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eh1zWQpjM6uv","colab_type":"code","colab":{}},"source":["# comprobamos que las tenemos disponibles en la carpeta actual\n","!ls -lah"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7xvHQ2wg_oJ6","colab_type":"code","colab":{}},"source":["# vamos a cargar y a mostrar algunas de las imágenes\n","import os\n","import numpy as np\n","from PIL import Image\n","# configuramos Colab para que nos muestre las imágenes más grandes\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (20,20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"SBmclpfM9G1G","colab_type":"code","colab":{}},"source":["# cargamos las imágenes como RGB y las convertimos a array\n","def load_image(filename):\n","\timage = Image.open(filename)\n","\timage = image.convert('RGB')\n","\tpixels = np.asarray(image)\n","\treturn pixels\n","\n","# cargamos las imágenes dentro de un directorio\n","def load_faces(directory, n_faces):\n","\tfaces = list()\n","\t# listamos los archivos\n","\tfor filename in os.listdir(directory):\n","\t\t# cargamos la imagen\n","\t\tpixels = load_image(directory + filename)\n","\t\t# la guardamos\n","\t\tfaces.append(pixels)\n","\t\t# paramos cuando llegamos a n_faces\n","\t\tif len(faces) >= n_faces:\n","\t\t\tbreak\n","\treturn np.asarray(faces)\n","\n","# para visualizar las imagenes\n","def plot_faces(faces, n):\n","\tfor i in range(n * n):\n","\t\tplt.subplot(n, n, 1 + i)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(faces[i])\n","\tplt.show()\n","\n","# carpeta donde estan nuestras imagenes descomprimidas\n","directory = 'img_align_celeba/'\n","# cargamos 25 imagenes para visualizarlas\n","faces = load_faces(directory, 25)\n","print('Loaded: ', faces.shape)\n","# y las mostramos\n","plot_faces(faces, 5)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mhEX5hX6Rc6O","colab_type":"text"},"source":["Ahora tenemos que extraer únicamente la cara de esas imágenes y guardarlas como nuestro nuevo dataset."]},{"cell_type":"code","metadata":{"id":"ByERFGYcCcRC","colab_type":"code","colab":{}},"source":["# vamos a utilizar MTCNN, que es un detector de caras, para extraer solo la\n","# porción de la imagen que contenga una cara, y luego guardaremos el dataset\n","!pip install mtcnn\n","from mtcnn.mtcnn import MTCNN\n","\n","# extraemos la cara de una imagen y la guardamos\n","def extract_face(model, pixels, required_size=(80, 80)):\n","\t# detectamos la cara\n","\tfaces = model.detect_faces(pixels)\n","\t# si no hay cara, paramos\n","\tif len(faces) == 0:\n","\t\treturn None\n","\t# obtenemos las dimensiones de la cara detectada\n","\tx1, y1, width, height = faces[0]['box']\n","\t# esto es un \"apaño\" para un bug que tiene la librería (a veces devuelve coords < 0)\n","\tx1, y1 = abs(x1), abs(y1)\n","\t# convertimos a coordenadas\n","\tx2, y2 = x1 + width, y1 + height\n","\t# cortamos la cara\n","\tface_pixels = pixels[y1:y2, x1:x2]\n","\t# redimensionamos al tamaño deseado\n","\timage = Image.fromarray(face_pixels)\n","\timage = image.resize(required_size)\n","\tface_array = np.asarray(image)\n","\treturn face_array\n","\n","# cargamos imágenes y extraemos la cara con la función anterior\n","def load_faces(directory, n_faces):\n","\t# preparamos el modelo que detecta las caras\n","\tmodel = MTCNN()\n","\tfaces = list()\n","\t# recorremos todos los archivos disponibles\n","\tfor filename in os.listdir(directory):\n","\t\t# cargamos la imagen\n","\t\tpixels = load_image(directory + filename)\n","\t\t# detectamos la cara\n","\t\tface = extract_face(model, pixels)\n","\t\tif face is None:\n","\t\t\tcontinue\n","\t\t# la guardamos\n","\t\tfaces.append(face)\n","\t\tprint(len(faces), face.shape)\n","\t\t# paramos cuando ya tenemos n_faces\n","\t\tif len(faces) >= n_faces:\n","\t\t\tbreak\n","\treturn np.asarray(faces)\n","\n","# carpeta con todas las imágenes\n","directory = 'img_align_celeba/'\n","# carga y extrae las caras de N imagenes\n","all_faces = load_faces(directory, 50000)\n","print('Loaded: ', all_faces.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AWvkOsrlbJU5","colab_type":"code","colab":{}},"source":["# guardamos el dataset para que sea más cómodo en el futuro\n","np.savez_compressed('img_align_celeba.npz', all_faces)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dlmavg-ZOQLN","colab_type":"code","colab":{}},"source":["# lo copiamos a nuestro Drive para no perderlo\n","!cp img_align_celeba.npz drive/My\\ Drive/img_align_celeba.npz\n","!ls -lah drive/My\\ Drive/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"smm-K23UDGc-","colab_type":"code","colab":{}},"source":["# si queremos recuperar el dataset, es así de fácil\n","import numpy as np\n","data = np.load('drive/My Drive/img_align_celeba.npz')\n","faces = data['arr_0']\n","print('Loaded: ', faces.shape)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"al_libiLRsNB","colab_type":"text"},"source":["¡Ya tenemos el dataset listo! Vamos a implementar nuestra GAN. Os daréis cuenta de que es siempre lo mismo, con ligeras variaciones dependiendo del tamaño de las imágenes:"]},{"cell_type":"markdown","metadata":{"id":"y_Mc-M95C2ws","colab_type":"text"},"source":["# Creamos nuestra GAN y la entrenamos"]},{"cell_type":"code","metadata":{"id":"bPeLBoinDGVg","colab_type":"code","colab":{}},"source":["# importamos las librerías necesarias\n","import numpy as np\n","from tensorflow.keras.datasets.cifar10 import load_data\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout\n","import matplotlib.pyplot as plt\n","plt.rcParams[\"figure.figsize\"] = (20,20)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"vZwSsm89GTgc","colab_type":"code","colab":{}},"source":["# definimos el discriminador\n","def define_discriminator(in_shape=(80,80,3)):\n","\tmodel = Sequential()\n","\t# normal\n","\tmodel.add(Conv2D(128, (5,5), padding='same', input_shape=in_shape))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample (por el atributo 'strides')\n","\tmodel.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# downsample\n","\tmodel.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n"," \t# downsample\n","\tmodel.add(Conv2D(128, (5,5), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# clasificador\n","\tmodel.add(Flatten())\n","\tmodel.add(Dropout(0.4))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\t# compilamos modelo\n","\topt = Adam(lr=0.0002, beta_1=0.5)\n","\tmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n","\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"k-x8dUj2GV02","colab_type":"code","colab":{}},"source":["# definimos el generador\n","def define_generator(latent_dim):\n","\tmodel = Sequential()\n","\tn_nodes = 128 * 5 * 5\n","\tmodel.add(Dense(n_nodes, input_dim=latent_dim))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\tmodel.add(Reshape((5, 5, 128)))\n","\t# upsample a 10x10\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample a 20x20\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# upsample a 40x40\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n"," \t# upsample a 80x80\n","\tmodel.add(Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))\n","\tmodel.add(LeakyReLU(alpha=0.2))\n","\t# salida (nuestra imagen fake)\n","\tmodel.add(Conv2D(3, (3,3), activation='tanh', padding='same'))\n","\treturn model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LLqkfLZhGXla","colab_type":"code","colab":{}},"source":["# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n","def define_gan(g_model, d_model):\n","    # Así que congelamos el discriminador:\n","    d_model.trainable = False\n","    # ahora conectamos el G(z) al D(x)\n","    model = Sequential()\n","    # añadimos el generador primero: él es el encargado de generar una muestra\n","    # a partir del espacio latente\n","    model.add(g_model)\n","    # y el discriminador después: le introducimos la muestra generada por el \n","    # G(z) para que nos diga si cree que es real o fake\n","    model.add(d_model)\n","    # y ahora sí, compilamos el modelo\n","    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5)) \n","    return model"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aA9vbUANG7uh","colab_type":"code","colab":{}},"source":["# definimos las funciones para cargar los datos\n","def load_real_samples():\n","    # cargamos los datos\n","    print('Loading data... this may take a while!')\n","    data = np.load('drive/My Drive/img_align_celeba.npz')\n","    print('Loading finished!')\n","    X = data['arr_0']\n","    # convertimos a float32\n","    X = X.astype('float32')\n","    # escalamos entre -1 y 1\n","    X = (X - 127.5) / 127.5\n","    return X\n","\n","# nos creamos una función que nos devuelva n_samples del dataset con sus etiquetas (1) \n","def generate_real_samples(dataset, n_samples):\n","    # seleccionamos n_samples muestras aleatoriamente\n","    ix = np.random.randint(0, dataset.shape[0], n_samples)\n","    # las cogemos\n","    X = dataset[ix]\n","    # generamos las etiquetas reales (1)\n","    y = np.ones((n_samples, 1))\n","    return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fE_OxdaAHJTS","colab_type":"code","colab":{}},"source":["# generamos los vectores latentes que introduciremos al generador\n","def generate_latent_points(latent_dim, batch_size):\n","    # generamos un vector de batch_size * latent_dim números aleatorios\n","    # latent_dim es la dimensión del vector latente\n","    # batch_size es el número de elementos por batch\n","    x_input = np.random.randn(latent_dim * batch_size)\n","    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n","    x_input = x_input.reshape(batch_size, latent_dim)\n","    return x_input\n","\n","# creamos datos fake con el generador (dinero falsificado)\n","def generate_fake_samples(g_model, latent_dim, n_samples): \n","    # usamos la función anterior para generar los vectores latentes que \n","    # necesitamos para generar muestras fake\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    # le introducimos los vectores latentes al generador para obtener\n","    # muestras similares a las reales\n","    X = g_model.predict(x_input)\n","    # le asignamos la etiqueta 1 (porque utilizaremos esta función para\n","    # entrenar el G y en ese caso queremos \"engañar\" al D)\n","    y = np.zeros((n_samples, 1)) \n","    return X, y"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4lwyWzu3HVc3","colab_type":"code","colab":{}},"source":["# función para guardar las imágenes generadas\n","def save_plot(examples, epoch, n=7):\n","\t# escalamos de [-1,1] (la salida de nuestra gan, debido a la función de activación tanh) a [0,1]\n","\texamples = (examples + 1) / 2.0\n","\tfor i in range(n * n):\n","\t\tplt.subplot(n, n, 1 + i)\n","\t\tplt.axis('off')\n","\t\tplt.imshow(examples[i])\n","\t# guardamos las imágenes\n","\tfilename = 'generated_plot_e%03d.png' % (epoch+1)\n","\tplt.savefig(filename)\n","\tplt.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wF-VEBxYHxvT","colab_type":"code","colab":{}},"source":["# función para entrenar la GAN: el discriminador y el generador\n","def train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=100, n_batch=128):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    half_batch = int(n_batch / 2)\n","    # bucle para las epochs\n","    for epoch in range(n_epochs):\n","        # bucle para los batch\n","        for batch in range(bat_per_epo):\n","            \n","            # en esta ocasión vamos a separar las pérdidas del discriminador\n","            # cuando le metemos imágenes reales y cuando le metemos imágenes\n","            # fake para ver cómo lo hace con cada tipo\n","            # recordad que lo ideal es que llegue a un 50% de acc en cada uno\n","\n","            # preparamos los datos reales\n","            X_real, y_real = generate_real_samples(dataset, half_batch)\n","            # actualizamos el discriminador\n","            d_loss1, _ = d_model.train_on_batch(X_real, y_real)\n","            \n","            # generamos datos falsos\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            # actualizamos el discriminador\n","            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)\n","\t\t\t\n","            # preparamos los puntos en el espacio latente: serán la entrada al\n","            # modelo GAN con el que entrenaremos el generador\n","            X_gan = generate_latent_points(latent_dim, n_batch)\n","            \n","            # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n","            # para que piense que las muestras que le introducimos son reales, y\n","            # en caso de que diga que no son reales, aprovechamos la información\n","            # de sus gradientes para actualizar el G(z) para que la próxima vez\n","            # los datos generados por G(z) sean más plausibles (parecidos a los \n","            # reales)\n","            y_gan = np.ones((n_batch, 1))\n","            \n","            # como acabamos de ver, entrenamos el generador de forma que actualice\n","            # sus pesos usando los gradientes del discriminador\n","            # tened en cuenta que en este modelo (gan_model) el discriminador está\n","            # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n","            # a nuestro policía, lo que queremos es fabricar dinero más realista.\n","            g_loss = gan_model.train_on_batch(X_gan, y_gan)\n","            \n","            # mostramos el progreso\n","            print('>%d, %d/%d, d1=%.3f, d2=%.3f g=%.3f' % (epoch+1, batch+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n","        # evaluate the model performance, sometimes\n","        if (epoch+1) % 10 == 0 or epoch == 0:\n","            # preparamos ejemplos reales\n","            X_real, y_real = generate_real_samples(dataset, n_batch)\n","            # evaluamos el discriminador con datos reales\n","            _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)\n","            # preparamos ejemplos fake\n","            x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_batch)\n","            # evaluamos el discriminador con datos fake\n","            _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)\n","            # mostramos cómo de bueno es nuestro policía\n","            print('>Accuracy real: %.0f%%, fake: %.0f%%' % (acc_real*100, acc_fake*100))\n","            # guardamos las imágenes generadas\n","            save_plot(x_fake, epoch)\n","            # guardamos el generador para tenerlo disponible más tarde\n","            filename = 'generator_model_%03d.h5' % (epoch + 1)\n","            g_model.save(filename)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tr-_KR-3vvXX","colab_type":"code","colab":{}},"source":["# size of the latent space\n","latent_dim = 100\n","# create the discriminator\n","d_model = define_discriminator()\n","# create the generator\n","g_model = define_generator(latent_dim)\n","# create the gan\n","gan_model = define_gan(g_model, d_model)\n","# load image data\n","dataset = load_real_samples()\n","# train model\n","train(g_model, d_model, gan_model, dataset, latent_dim, n_epochs=150, n_batch=256)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NNV35ZAlDN0L","colab_type":"text"},"source":["# Guardamos los modelos e imagenes en nuestro Drive"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"by0agJ2cHEJZ","colab":{}},"source":["# veamos los archivos generados\n","!ls -lah"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5QDqCQn-ouZ","colab_type":"code","colab":{}},"source":["# los guardamos en nuestro drive para evitar tener que reejecutar cada vez\n","!mkdir drive/My\\ Drive/6_latent_space\n","!cp *gen* drive/My\\ Drive/6_latent_space/\n","!ls -lah drive/My\\ Drive/6_latent_space/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c6ZdPQMoDaUS","colab_type":"text"},"source":["# Visualizamos los datos que es capaz de generar nuestra GAN"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_33hq23eHDwA","colab":{}},"source":["import numpy as np\n","latent_dim = 100\n","n_samples = 100\n","\n","# definimos el mismo código latente para todos los tests\n","latent_points = generate_latent_points(latent_dim, n_samples)\n","# y los guardamos\n","np.savez_compressed('latent_points.npz', latent_points)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_jQnrWmqHDsu","colab":{}},"source":["g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_010.h5')\n","X = g_model.predict(latent_points)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"xNzpqra-HDou","colab":{}},"source":["X.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KOu0_u85HDjA","colab":{}},"source":["def plot_results(imgs, n_rows, n_cols, epoch, h=80, w=80):\n","    imgs = (imgs + 1) / 2.0\n","    output_img = np.zeros((n_rows*h, n_cols*w, 3), np.float)\n","    k = 0\n","    for i in range(n_rows):\n","        for j in range(n_cols):\n","            output_img[h*i:h*(i+1), w*j:w*(j+1), :] = imgs[k]\n","            k += 1\n","    plt.imshow(np.asarray(output_img*255., np.uint8))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKHp4yuQlAFa","colab_type":"code","colab":{}},"source":["plot_results(X, 8, 8, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7noecHKsluGw","colab_type":"code","colab":{}},"source":["# veamos el modelo 50\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_050.h5')\n","X = g_model.predict(latent_points)\n","plot_results(X, 8, 8, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9B1AliQ_mBtj","colab_type":"code","colab":{}},"source":["# el 100\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_100.h5')\n","X = g_model.predict(latent_points)\n","plot_results(X, 8, 8, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HiJAR2HJTrUn","colab_type":"code","colab":{}},"source":["# el 150\n","g_model = define_generator(latent_dim)\n","g_model.load_weights('generator_model_150.h5')\n","X = g_model.predict(latent_points)\n","plot_results(X, 8, 8, 100)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ccEBscXhICNi","colab_type":"text"},"source":["# Interpolando entre dos puntos de nuestro espacio latente..."]},{"cell_type":"code","metadata":{"id":"g0l4gdMeIM6C","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","\n","# uniform interpolation between two points in latent space\n","def interpolate_points(p1, p2, n_steps=10):\n","\t# interpolate ratios between the points\n","\tratios = np.linspace(0, 1, num=n_steps)\n","\t# linear interpolate vectors\n","\tvectors = list()\n","\tfor ratio in ratios:\n","\t\tv = (1.0 - ratio) * p1 + ratio * p2\n","\t\tvectors.append(v)\n","\treturn np.asarray(vectors)\n","\n","# create a plot of generated images\n","def plot_generated(examples, n, figsize=(20, 20)):\n","\tplt.figure(figsize=figsize)\n","    # plot images\n","\tfor i in range(n):\n","\t\t# define subplot\n","\t\tplt.subplot(1, n, 1 + i)\n","\t\t# turn off axis\n","\t\tplt.axis('off')\n","\t\t# plot raw pixel data\n","\t\tplt.imshow(examples[i, :, :])\n","\tplt.show()\n","\n","# cargamos el modelo\n","model = tf.keras.models.load_model('generator_model_050.h5')\n","# obtenemos la codificación de 2 puntos en nuestro espacio latente\n","pts = generate_latent_points(100, 2)\n","# los interpolamos\n","interpolated = interpolate_points(pts[0], pts[1])\n","# generamos las imágenes\n","X = model.predict(interpolated)\n","# escalamos de [-1,1] a [0,1] (por la salida tanh)\n","X = (X + 1) / 2.0\n","# mostramos los resultados\n","plot_generated(X, len(interpolated), figsize=(24, 24))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TNy0mpAOw9p","colab_type":"text"},"source":["# Ejemplo de \"vector arithmetic\""]},{"cell_type":"code","metadata":{"id":"wp8it6v3UdY2","colab_type":"code","colab":{}},"source":["# create a plot of generated images\n","def plot_generated(examples, rows, cols, figsize=(20,20)):\n","\t# plot images\n","\tplt.figure(figsize=figsize)\n","\tfor i in range(rows * cols):\n","\t\t# define subplot\n","\t\tplt.subplot(rows, cols, 1 + i)\n","\t\t# turn off axis\n","\t\tplt.axis('off')\n","\t\t# plot raw pixel data\n","\t\tplt.imshow(examples[i, :, :])\n","\tplt.show()\n","\n","# load model\n","model = tf.keras.models.load_model('generator_model_150.h5')\n","\n","# load the saved latent points\n","data = np.load('latent_points.npz')\n","points = data['arr_0']\n","\n","# creamos las imágenes con esos vectores latentes\n","images = model.predict(points)\n","\n","# representamos\n","images = (images + 1) / 2.0\n","plot_generated(images, 10, 10)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"PjAwrBQ9Wh5J","colab_type":"code","colab":{}},"source":["# elegimos 3 representantes de:\n","# mujeres sonriendo\n","# mujeres neutrales\n","# hombres neutrales\n","\n","# average list of latent space vectors\n","def average_points(points, ix):\n","\t# convert to zero offset points\n","\tzero_ix = [i-1 for i in ix]\n","\t# retrieve required points\n","\tvectors = points[zero_ix]\n","\t# average the vectors\n","\tavg_vector = np.mean(vectors, axis=0)\n","\t# combine original and avg vectors\n","\tall_vectors = np.vstack((vectors, avg_vector))\n","\treturn all_vectors\n","\n","# los representantes\n","smiling_woman_ix = [14, 20, 45]\n","neutral_woman_ix = [8, 24, 77]\n","neutral_man_ix = [5, 42, 93]\n","\n","# load the saved latent points\n","data = np.load('latent_points.npz')\n","points = data['arr_0']\n","\n","# average vectors\n","smiling_woman = average_points(points, smiling_woman_ix)\n","neutral_woman = average_points(points, neutral_woman_ix)\n","neutral_man = average_points(points, neutral_man_ix)\n","\n","# combine all vectors\n","all_vectors = np.vstack((smiling_woman, neutral_woman, neutral_man))\n","\n","# generate images\n","images = model.predict(all_vectors)\n","\n","# scale pixel values\n","images = (images + 1) / 2.0\n","plot_generated(images, 3, 4)\n","\n","# smiling woman - neutral woman + neutral man = smiling man\n","result_vector = smiling_woman[-1] - neutral_woman[-1] + neutral_man[-1]\n","\n","# generate image\n","result_vector = np.expand_dims(result_vector, 0)\n","result_image = model.predict(result_vector)\n","\n","# scale pixel values\n","result_image = (result_image + 1) / 2.0\n","plt.figure(figsize=(5, 5))\n","plt.imshow(result_image[0])\n","plt.title('Man smiling')\n","plt.axis('off')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QJfof3VUVJHD","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}