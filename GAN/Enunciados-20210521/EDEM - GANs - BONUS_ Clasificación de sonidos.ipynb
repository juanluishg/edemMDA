{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"EDEM - GANs - BONUS: Clasificación de sonidos.ipynb","provenance":[{"file_id":"1ZrSDufPG51OJyAk2oufK0-MV6NTOSGV7","timestamp":1585803882989}],"collapsed_sections":[],"authorship_tag":"ABX9TyMDyrb9UoGLPuY+pcx3j2sL"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"57qW9mJ3uecY","colab_type":"code","colab":{}},"source":["# Fuente: https://github.com/adanRivas/CNN-Audio-Classifier-with-Keras-Tensorflow/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zjD45XR-uF5K","colab_type":"text"},"source":["# Descargamos y preparamos los datos"]},{"cell_type":"code","metadata":{"id":"mUAsd9vADck8","colab_type":"code","colab":{}},"source":["# descargamos el dataset que utilizaremos (https://github.com/karoldvl/ESC-50/)\n","!wget https://github.com/karoldvl/ESC-50/archive/master.zip\n","!unzip master.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"grgWVf_4trRo","colab_type":"code","colab":{}},"source":["!ls -la"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QFHiar7NtOve","colab_type":"code","colab":{}},"source":["# load python libraries\n","%matplotlib inline\n","import numpy as np\n","import pandas as pd\n","import random\n","from scipy.io import wavfile\n","from sklearn.preprocessing import scale\n","import librosa.display\n","import librosa\n","import matplotlib.pyplot as plt\n","import os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"tnrlcnK4tVCP","colab_type":"code","colab":{}},"source":["def save_melspectrogram(directory_path, file_name, dataset_split, label, sampling_rate=44100):\n","    \"\"\" Will save spectogram into current directory\"\"\"\n","    \n","    path_to_file = os.path.join(directory_path, file_name)\n","    data, sr = librosa.load(path_to_file, sr=sampling_rate, mono=True)\n","    data = scale(data)\n","\n","    melspec = librosa.feature.melspectrogram(y=data, sr=sr, n_mels=128)\n","    # Convert to log scale (dB) using the peak power (max) as reference\n","        # per suggestion from Librbosa: https://librosa.github.io/librosa/generated/librosa.feature.melspectrogram.html\n","    log_melspec = librosa.power_to_db(melspec, ref=np.max)  \n","    librosa.display.specshow(log_melspec, sr=sr)\n","    \n","    # create saving directory\n","    directory = './ESC-50-master/melspectrograms/{dataset}/{label}'.format(dataset=dataset_split, label=label)\n","    os.makedirs(directory, exist_ok=True)\n","    \n","    plt.savefig(directory + '/' + file_name.strip('.wav') + '.png')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"o3vg34vjtXh8","colab_type":"code","colab":{}},"source":["def _train_test_split(filenames, train_pct):\n","    \"\"\"Create train and test splits for ESC-50 data\"\"\"\n","    random.seed(2018)\n","    n_files = len(filenames)\n","    n_train = int(n_files*train_pct)\n","    train = np.random.choice(n_files, n_train, replace=False)\n","        \n","    # split on training indices\n","    training_idx = np.isin(range(n_files), train)\n","    training_set = np.array(filenames)[training_idx]\n","    testing_set = np.array(filenames)[~training_idx]\n","    print('\\tfiles in training set: {}, files in testing set: {}'.format(len(training_set), len(testing_set)))\n","    \n","    return {'training': training_set, 'testing': testing_set}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oeBqbhL_tcSQ","colab_type":"code","colab":{}},"source":["dataset_dir = './ESC-50-master'\n","\n","# Load meta data for audio files\n","meta_data = pd.read_csv(dataset_dir + '/meta/esc50.csv')\n","\n","labs = meta_data.category\n","unique_labels = labs.unique()\n","print(unique_labels)\n","meta_data.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xjvGn9nITZ5j","colab_type":"code","colab":{}},"source":["# interesting sounds\n","interesting_sounds_idx = [20, 21, 22, 23, 24, 25, 26, 27, 28, 29]\n","interesting_sounds = ['crying_baby', 'sneezing', 'clapping', 'breathing', 'coughing', 'footsteps', 'laughing', 'brushing_teeth', 'snoring', 'drinking_sipping']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"YfnMQ0Ett8ME","colab_type":"code","colab":{}},"source":["# usamos concurrent para hacerlo en paralelo\n","import concurrent\n","from tqdm import tqdm\n","\n","def compute_and_save_mel_spectogram(data):\n","    directory_path, filename, dataset_split, label = data\n","    save_melspectrogram(directory_path, filename, dataset_split, label, sampling_rate=44100)\n","    return filename\n","\n","results = []\n","\n","for label in interesting_sounds:\n","    print('\\nProccesing {} audio files'.format(label))\n","    current_label_meta_data = meta_data[meta_data.category == label]\n","    datasets = _train_test_split(current_label_meta_data.filename, train_pct=0.8)\n","    for dataset_split, audio_files in datasets.items():\n","        n_audio_files = len(audio_files)\n","        directory_path = dataset_dir + '/audio/'\n","        data = list(zip([directory_path] * n_audio_files,  audio_files, [dataset_split] * n_audio_files, [label] * n_audio_files))\n","        \n","        # Create a pool of processes. By default, one is created for each CPU in your machine.\n","        with concurrent.futures.ProcessPoolExecutor() as executor:\n","            # Process the list of files, but split the work across the process pool to use all CPUs!\n","            for out_fn in tqdm(executor.map(compute_and_save_mel_spectogram, data), total=len(data)):\n","                results.append(out_fn)\n","        "],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"muSFRIUwa8lh","colab_type":"code","colab":{}},"source":["!ls -lah ./ESC-50-master/melspectrograms/*/*"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"a6V1dgl7uKUg","colab_type":"text"},"source":["# Creamos el modelo y lo entrenamos"]},{"cell_type":"code","metadata":{"id":"3vGEmSE2uN5s","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input\n","from tensorflow.keras.preprocessing import image\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Dense, Dropout, Flatten, Input\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras import metrics\n","from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n","from time import time\n","import numpy as np\n","import json"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"udeOYQl5fVME","colab":{}},"source":["# Establecemos parámetros\n","\n","batch_size = 40\n","epochs = 200\n","\n","# dimensions of our images.\n","img_width, img_height = 224, 224\n","\n","input_tensor = Input(shape=(224,224,3))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"aqqlx9V_uYZi","colab_type":"code","colab":{}},"source":["# configuramos los generadores\n","\n","# training generator configuration\n","training_data_dir = './ESC-50-master/melspectrograms/training'\n","\n","training_datagen = image.ImageDataGenerator(\n","    rescale=1./255)\n","\n","training_generator = training_datagen.flow_from_directory(\n","    training_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size)\n","\n","# validation generator configuration\n","validation_data_dir ='./ESC-50-master/melspectrograms/testing/'\n","\n","validation_datagen = image.ImageDataGenerator(\n","    rescale=1./255)\n","\n","validation_generator = validation_datagen.flow_from_directory(\n","    validation_data_dir,\n","    target_size=(img_height, img_width),\n","    batch_size=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uUT2uZwlcGNE","colab_type":"code","colab":{}},"source":["nb_training_samples = 372\n","nb_validation_samples = 130"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Us4OPmlDulrv","colab_type":"code","colab":{}},"source":["# cargamos el modelo base\n","base_model = VGG16(weights='imagenet', include_top=False, input_tensor=input_tensor)\n","print('Model loaded.')\n","base_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OX2S_jPMuoP7","colab_type":"code","colab":{}},"source":["# build a classifier model to put on top of the convolutional model\n","top_model = Sequential()\n","top_model.add(Flatten(input_shape=base_model.output_shape[1:]))\n","top_model.add(Dense(256, activation='relu'))\n","top_model.add(Dropout(0.5))\n","top_model.add(Dense(10, activation='softmax'))\n","top_model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pcWy0uexut36","colab_type":"code","colab":{}},"source":["# top_model.load_weights('bootlneck_fc_model.h5')\n","model = Model(inputs=base_model.input, outputs=top_model(base_model.output))\n","model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LNfb4K9fuvww","colab_type":"code","colab":{}},"source":["num_layers_to_freeze = 15\n","\n","def top_5_accuracy(y_true, y_pred):\n","    return metrics.top_k_categorical_accuracy(y_true, y_pred, k=5)\n","\n","for layer in model.layers[:num_layers_to_freeze]:\n","    layer.trainable = False\n","\n","# definimos el optimizador\n","# optimizer = SGD(lr=1e-4, momentum=0.9, decay=1e-6, nesterov=True)  # con nesterov y weight decay\n","optimizer = SGD(lr=1e-4, momentum=0.9) # sin nesterov\n","model.compile(optimizer=optimizer, \n","                      loss='categorical_crossentropy', \n","                      metrics=['acc', top_5_accuracy])\n","\n","# serialize model to JSON\n","model_json = model.to_json()\n","model_filename = \"vgg16_model_{}_frozen_layers.json\".format(num_layers_to_freeze)\n","with open(model_filename, \"w\") as json_file:\n","    json_file.write(model_json)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"XFWJxmb4u0vf","colab_type":"code","colab":{}},"source":["tensorboard = TensorBoard(log_dir=\"logs/layers_frozen_{}\".format(num_layers_to_freeze))\n","\n","# checkpoint\n","filepath=\"esc50_vgg16_stft_weights_train_last_2_base_layers.best.hdf5\"\n","best_model_checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n","callbacks_list = [best_model_checkpoint, tensorboard]\n","\n","model.fit_generator(\n","    training_generator,\n","    steps_per_epoch=nb_training_samples/batch_size,\n","    epochs=epochs,\n","    validation_data=validation_generator,\n","    validation_steps=nb_validation_samples/batch_size,\n","    callbacks=callbacks_list)\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WHYOF7an1ty2","colab_type":"text"},"source":["# Evaluamos el modelo"]},{"cell_type":"code","metadata":{"id":"fCOfn_Mqtu9v","colab_type":"code","colab":{}},"source":["ls -lah ./ESC-50-master/melspectrograms/testing/coughing/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WI3RLTN5u4Un","colab_type":"code","colab":{}},"source":["# Get top k predictions for selected test files\n","import json\n","\n","def get_top_k_predictions(preds, label_map, k=5, print_flag=False):\n","    sorted_array = np.argsort(preds)[::-1]\n","    top_k = sorted_array[:k]\n","    label_map_flip = dict((v,k) for k,v in label_map.items())\n","    \n","    y_pred = []\n","    for label_index in top_k:\n","        if print_flag:\n","            print(\"{} ({})\".format(label_map_flip[label_index], preds[label_index]))\n","        y_pred.append(label_map_flip[label_index])\n","        \n","    return y_pred\n","\n","label_map = (training_generator.class_indices)\n"," \n","json_content = json.dumps(label_map)\n","f = open(\"cough_label_map.json\",\"w\")\n","f.write(json_content)\n","f.close()\n","\n","img_path = './ESC-50-master/melspectrograms/testing/coughing/1-19118-A-24.png'\n","\n","img = image.load_img(img_path, target_size=(224, 224))\n","x = image.img_to_array(img)\n","x = np.expand_dims(x, axis=0)* 1./255\n","\n","preds = model.predict(x)[0]\n","\n","get_top_k_predictions(preds, label_map, k=3)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wyRUTMBevA4u","colab_type":"code","colab":{}},"source":["# Calculate and plot confusion matrix\n","\n","import itertools\n","import matplotlib.pyplot as plt\n","\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","#     print(cm)\n","    plt.figure(figsize=(24,24))\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=90)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.tight_layout()\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","\n","import os\n","from sklearn.metrics import confusion_matrix\n","\n","testing_dir = './ESC-50-master/melspectrograms/testing/'\n","\n","y_true = []\n","y_pred = []\n","for label in label_map.keys():\n","    file_list = os.listdir(testing_dir + label)\n","    for file_name in file_list:\n","        img_path = testing_dir + label + '/' + file_name\n","        \n","        img = image.load_img(img_path, target_size=(224, 224))\n","        \n","        x = image.img_to_array(img)\n","        x = np.expand_dims(x, axis=0)* 1./255\n","        \n","        preds = model.predict(x)[0]\n","        \n","        y_true.append(label)\n","        y_pred.append(get_top_k_predictions(preds, label_map, k=1)[0])\n","        \n","cm = confusion_matrix(y_true, y_pred)\n","plot_confusion_matrix(cm, sorted(label_map.keys()), normalize=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_gYR1qxtuVbo","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}