{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XsGrf4SGApQ"
   },
   "source": [
    "**PRÁCTICA**: implementar una GAN que genere parejas de números que cumplan (x, x^2).\n",
    "\n",
    "**NOTA**: escoger TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzapMYChWU-E"
   },
   "source": [
    "# Mi primera GAN\n",
    "\n",
    "En este Notebook vamos a implementar nuestra primera GAN. Recordad la arquitectura:\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/2426/1*XKanAdkjQbg1eDDMF2-4ow.png\"></center>\n",
    "\n",
    "Como ya hemos visto, una GAN consta de un generador (*el falsificador)* y un discriminador (*el policía*).\n",
    "\n",
    "Vamos a comenzar con un ejemplo muy sencillo que iremos complicando conforme avancemos. En esta ocasión no vamos a crear dinero, sino que vamos a generar nuevas muestras que encajen en la función $x^2$. Las muestras reales (nuestro dataset) son las que véis dibujadas en la gráfica siguiente:\n",
    "\n",
    "<center><img src=\"http://mathcentral.uregina.ca/QQ/database/QQ.09.06/mike1.1.gif\"></center>\n",
    "\n",
    "Así que lo primero que vamos a hacer es crear una función que nos permita generar dichas muestras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LI0-C8N-Y4hF"
   },
   "outputs": [],
   "source": [
    "# importamos lo que vamos a necesitar\n",
    "import numpy as np\n",
    "from numpy.random import rand, randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "blfu5NVyYBH7"
   },
   "outputs": [],
   "source": [
    "# generamos muestras reales con sus correspondientes etiquetas (1)\n",
    "def generate_real_samples(n):\n",
    "    # vamos a generar datos entre -0.5 y 0.5\n",
    "    X1 = rand(n) - 0.5\n",
    "    # nuestros datos son x^2\n",
    "    X2 = X1 * X1\n",
    "    # stack arrays\n",
    "    X1 = X1.reshape(n, 1)\n",
    "    X2 = X2.reshape(n, 1)\n",
    "    X = np.hstack((X1, X2))\n",
    "    # generate class labels\n",
    "    y = np.ones((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "oMRAW2QRY7c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generamos nuestro dataset\n",
    "X, y = generate_real_samples(n=100)\n",
    "# plot samples\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdbPpUXUZ0gN"
   },
   "source": [
    "Nuestra meta en este caso es ser capaces de generar nuevas parejas de datos $(x, x^2)$ lo más similares posibles a los que generaría la función $f(x)=x^2, x \\in [-0.5, 0.5]$.\n",
    "\n",
    "Vamos a crear primero nuestro discriminador. Lo primero es pensar cuales van a ser las entradas y cuales las salidas. Veamos:\n",
    "\n",
    "Las entradas serán parejas $(x, x^2)$ entre -0.5 y 0.5. Por ejemplo: $(0.2, 0.04)$, $(0.4, 0.16)$, $(-0.2, 0.04)$, $(-0.4, -0.16)$, etc.\n",
    "\n",
    "La salida será un valor binario: 1 si la pareja $(x, x^2)$ realmente se parece a la función $f(x)=x^2$, 0 en caso contrario.\n",
    "\n",
    "Vamos a definirlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8idxYnPYa5_y"
   },
   "outputs": [],
   "source": [
    "# definimos el discriminador\n",
    "def define_discriminator(n_inputs=2):\n",
    "    model = Sequential()\n",
    "    # Nuestro discriminador va a ser muy sencillo: va a tener 2 capas densas.\n",
    "    # la primera, tendrá 25 neuronas, activación relu e inicialización 'he_uniform' (https://keras.io/initializers/)\n",
    "    # además, tendremos que indicarle las dimensiones de entrada (con el atributo input_dim)\n",
    "    model.add(Dense(N_NEURONAS, activation='ACTIVACIÓN', kernel_initializer='INICIALIZACIÓN_PESOS', input_dim=DIMENSIONES_ENTRADA))\n",
    "    # la segunda, será una densa de 1 única neurona y activación sigmoide: \n",
    "    # queremos que nos de la probabilidad de que la imagen sea real\n",
    "    model.add(Dense(N_NEURONAS, activation='ACTIVACIÓN'))\n",
    "    # utilizamos función de activación final sigmoide y la cross entropía\n",
    "    # binaria para que la red nos devuelva las probabilidades de que la entrada\n",
    "    # sea falsa y real\n",
    "    # el optimizador que usaremos en este caso es el adam con los parámetros por defecto\n",
    "    model.compile(loss='AQUÍ_LA_FUNCIÓN_DE_PÉRDIDAS', optimizer='OPTIMIZADOR', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qt1L-2ybrma"
   },
   "source": [
    "Perfecto, ya lo tenemos.\n",
    "\n",
    "Ahora necesitamos el generador. ¿Qué es lo que necesitamos que haga el generador? Que genere 2 números que vamos a intentar aproximar a $(x, x^2)$ mediante entrenamiento.\n",
    "\n",
    "Vamos a ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uuXmHlE7b7kS"
   },
   "outputs": [],
   "source": [
    "# definimos el generador\n",
    "def define_generator(latent_dim, n_outputs=2):\n",
    "    # fijaos en varios detalles:\n",
    "    # - latent_dim: es el tamaño del vector de ruido de la entrada. \n",
    "    # Cuanto mayor sea, más complejos serán los datos que podremos generar\n",
    "    # - la función de activación final ha de ser lineal: esto es muy importante, \n",
    "    # ya que estamos haciendo un trabajo de regresión (estamos tratando de\n",
    "    # llegar a $(x, x^2)$ desde el valor introducido a la red (el vector latente)\n",
    "    # - no compilamos el modelo: esto se debe a que durante el entrenamiento \n",
    "    # del G(z) vamos a necesitar acoplar G(z) a D(x)\n",
    "\n",
    "    # vamos a definir un modelo haciendo uso del modelo Sequential de keras\n",
    "    model = MODELO\n",
    "    # le añadiremos una capa densa de 15 neuronas, con activación relu e\n",
    "    # inicialización de pesos 'he_uniform', y tendremos que indicarle las \n",
    "    # dimensiones de entrada, igual que en el caso del discriminador\n",
    "    model.add(AQUÍ_TU_CAPA) \n",
    "    # la última capa tendrá tantas neuronas como números esperamos generar\n",
    "    # (en este caso x y x^2) y activación lineal\n",
    "    model.add(AQUÍ_TU_CAPA)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbRHRFr9dEgH"
   },
   "source": [
    "Generador definido. Ahora vamos a combinar el generador y el discriminador para crear el modelo Generativo Adversarial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wAt6NsGVdMWX"
   },
   "outputs": [],
   "source": [
    "# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n",
    "def define_gan(generator, discriminator):\n",
    "    # recordad que durante el entrenamiento del generador necesitamos al\n",
    "    # discriminador para que nos diga si la muestra es real o no, pero\n",
    "    # no debemos actualizar los pesos del discriminador, ya que si no,\n",
    "    # estaríamos haciendo trampas: estaríamos haciendo peor al D(x)\n",
    "    # Así que congelamos el discriminador:\n",
    "    discriminator.trainable = HACER_QUE_NO_SEA_ENTRENABLE\n",
    "    # ahora conectamos el G(z) al D(x)\n",
    "    model = Sequential()\n",
    "    # añadimos el generador primero: él es el encargado de generar una muestra\n",
    "    # a partir del espacio latente\n",
    "    model.add(MODELO_A_AÑADIR)\n",
    "    # y el discriminador después: le introducimos la muestra generada por el \n",
    "    # G(z) para que nos diga si cree que es real o fake\n",
    "    model.add(MODELO_A_AÑADIR)\n",
    "    # y ahora sí, compilamos el modelo con optimizador adam y función de\n",
    "    # pérdidas binary crossentropy\n",
    "    COMPILAR MODELO CONFORME SE ESPECIFICA\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kx9ocDfd2eO"
   },
   "source": [
    "Bueno, ya lo tenemos todo, ¿no?\n",
    "\n",
    "Pues casi, pero no: nos faltan un par de funciones, una que nos devuelva el vector latente que introducirle al G(z) y otra que coja ese vector latente y produzca una muestra fake. \n",
    "\n",
    "Fijaos lo sencillo que es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q4Rjb3TheBbQ"
   },
   "outputs": [],
   "source": [
    "# generamos los vectores latentes que introduciremos al generador\n",
    "def generate_latent_points(latent_dim, batch_size):\n",
    "    # generamos un vector de batch_size * latent_dim números aleatorios\n",
    "    # latent_dim es la dimensión del vector latente\n",
    "    # batch_size es el número de elementos por batch\n",
    "    x_input = randn(latent_dim * batch_size)\n",
    "    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n",
    "    x_input = x_input.reshape(batch_size, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# creamos datos fake con el generador (dinero falsificado)\n",
    "def generate_fake_samples(generator, latent_dim, n): \n",
    "    # usamos la función anterior para generar los vectores latentes que \n",
    "    # necesitamos para generar muestras fake\n",
    "    # queremos generar 'n' códigos latentes de 'latent_dim'\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    # le introducimos los vectores latentes al generador para obtener\n",
    "    # muestras similares a las reales\n",
    "    X = generator.predict(x_input)\n",
    "    # le asignamos la etiqueta 0 (porque son falsas)\n",
    "    y = np.zeros((n, 1)) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIFHKIGWfKks"
   },
   "source": [
    "¡Ahora sí! Ya solo nos falta implementar el bucle de entrenamiento. Vamos a ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yx9Fe0AlfOqO"
   },
   "outputs": [],
   "source": [
    "# función para entrenar la GAN: el discriminador y el generador\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "    # para entrenar el discriminador, le introduciremos la mitad de los datos\n",
    "    # reales y la otra mitad falsa\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "        # preparamos los datos reales (generados con f(x)=x^2)\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        \n",
    "        # preparamos los datos falsos (creados con el generador)\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        \n",
    "        # entrenamos el discriminador\n",
    "        d_model.train_on_batch(x_real, y_real) # primero con los datos reales\n",
    "        d_model.train_on_batch(RELLENAR) # luego con los datos fake\n",
    "        \n",
    "        # preparamos los puntos en el espacio latente: serán la entrada al\n",
    "        # modelo GAN con el que entrenaremos el generador\n",
    "        x_gan = GENERAR_CÓDIGOS_LATENTES\n",
    "        \n",
    "        # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n",
    "        # para que piense que las muestras que le introducimos son reales, y\n",
    "        # en caso de que diga que no son reales, aprovechamos la información\n",
    "        # de sus gradientes para actualizar el G(z) para que la próxima vez\n",
    "        # los datos generados por G(z) sean más plausibles (parecidos a los \n",
    "        # reales)\n",
    "        y_gan = np.ones((n_batch, VALOR_ETIQUETA))\n",
    "        \n",
    "        # como acabamos de ver, entrenamos el generador de forma que actualice\n",
    "        # sus pesos usando los gradientes del discriminador\n",
    "        # tened en cuenta que en este modelo (gan_model) el discriminador está\n",
    "        # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n",
    "        # a nuestro policía, lo que queremos es fabricar dinero más realista.\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # evaluamos el modelo cada n_eval épocas\n",
    "        if (epoch+1) % n_eval == 0 or epoch == 0:\n",
    "            # preparamos ejemplos reales\n",
    "            x_real, y_real = generate_real_samples(n_batch)\n",
    "            # evaluamos el discriminador con datos reales\n",
    "            _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "            # preparamos ejemplos fake\n",
    "            x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)\n",
    "            # evaluamos el discriminador con datos fake\n",
    "            _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "            # mostramos cómo de bueno es nuestro policía\n",
    "            print(epoch, acc_real, acc_fake)\n",
    "            # lo ploteamos\n",
    "            plt.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
    "            plt.scatter(x_fake[:, 0], x_fake[:, 1], color='blue') \n",
    "            # lo guardamos para tenerlo disponible más tarde\n",
    "            filename = 'generated_plot_e%03d.png' % (epoch+1) \n",
    "            plt.savefig(filename)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vQ7top0De_tn"
   },
   "outputs": [],
   "source": [
    "# comenzamos con el entrenamiento\n",
    "\n",
    "# tamaño del espacio latente\n",
    "latent_dim = 5\n",
    "# creamos el discriminador\n",
    "discriminator = CREAR_MODELO_DISCRIMINADOR\n",
    "# creamos el generador\n",
    "generator = CREAR_MODELO_GENERADOR\n",
    "# creamos la GAN\n",
    "gan_model = CREAR_MODELO_GAN\n",
    "# entrenamos!\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-59Xwidifpe"
   },
   "source": [
    "Vamos a ver cómo ha ido el entrenamiento de nuestra red. Para ello, vamos a visualizar la salida del generador al principio, cuando aún no estaba entrenada, y al final, cuando ya estaba entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OxUN_1Jogr1J"
   },
   "outputs": [],
   "source": [
    "ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j0H7eRmCGR01"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e0001.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "We94v8QvhCPx"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e2000.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OdSU3tQ_huoX"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e10000.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH6r217nkec-"
   },
   "source": [
    "¡Fijáos! El generador ha aprendido a generar datos practicamente iguales a los de nuestro dataset original. ¿Os dáis cuenta de la potencia de esto? Y este es el ejemplo más sencillo que he podido poner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUqEw6gniDn-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMn5uHBmNGca69ep+os7DDx",
   "collapsed_sections": [],
   "name": "EDEM - GANs - 1. Mi primera GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
