{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2XsGrf4SGApQ"
   },
   "source": [
    "**PRÁCTICA**: implementar una GAN que genere parejas de números que cumplan (x, x^2).\n",
    "\n",
    "**NOTA**: escoger TPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qzapMYChWU-E"
   },
   "source": [
    "# Mi primera GAN\n",
    "\n",
    "En este Notebook vamos a implementar nuestra primera GAN. Recordad la arquitectura:\n",
    "\n",
    "<center><img src=\"https://miro.medium.com/max/2426/1*XKanAdkjQbg1eDDMF2-4ow.png\"></center>\n",
    "\n",
    "Como ya hemos visto, una GAN consta de un generador (*el falsificador)* y un discriminador (*el policía*).\n",
    "\n",
    "Vamos a comenzar con un ejemplo muy sencillo que iremos complicando conforme avancemos. En esta ocasión no vamos a crear dinero, sino que vamos a generar nuevas muestras que encajen en la función $x^2$. Las muestras reales (nuestro dataset) son las que véis dibujadas en la gráfica siguiente:\n",
    "\n",
    "<center><img src=\"http://mathcentral.uregina.ca/QQ/database/QQ.09.06/mike1.1.gif\"></center>\n",
    "\n",
    "Así que lo primero que vamos a hacer es crear una función que nos permita generar dichas muestras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "LI0-C8N-Y4hF"
   },
   "outputs": [],
   "source": [
    "# importamos lo que vamos a necesitar\n",
    "import numpy as np\n",
    "from numpy.random import rand, randn\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "blfu5NVyYBH7"
   },
   "outputs": [],
   "source": [
    "# generamos muestras reales con sus correspondientes etiquetas (1)\n",
    "def generate_real_samples(n):\n",
    "    # vamos a generar datos entre -0.5 y 0.5\n",
    "    X1 = rand(n) - 0.5\n",
    "    # nuestros datos son x^2\n",
    "    X2 = X1 * X1\n",
    "    # stack arrays\n",
    "    X1 = X1.reshape(n, 1)\n",
    "    X2 = X2.reshape(n, 1)\n",
    "    X = np.hstack((X1, X2))\n",
    "    # generate class labels\n",
    "    y = np.ones((n, 1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "oMRAW2QRY7c6",
    "outputId": "74128878-8df4-4601-b4d4-58f6fd0e5919"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcbUlEQVR4nO3dcYycd53f8ffHm3VuE+5YQ6y7y8aOw5ELF9fgLXtJquigcIEEVXG2uYCTEjVIkSJ6F7UEsOSIiNgmLQaL5k4iUhMdSHeQJg6Gbm0lyHAYWik9R17f2lgb6sPJgeOBFl/ipWq9JOvdb//YmWU8fmbm2d2ZeZ555vOSVpl5nmec37Mef+c339/v9/0pIjAzs+JakXUDzMysvRzozcwKzoHezKzgHOjNzArOgd7MrOAuyroBtS677LJYt25d1s0wM+sqhw8f/seIWJ10LneBft26dYyPj2fdDDOzriLpp/XOOXVjZlZwqQK9pFskHZd0QtLWhPOflPSipB9K+p6kK6vOzUo6Uv7Z28rGm5lZc01TN5L6gMeADwCngEOS9kbEi1WXTQAjEXFW0r8BvghsLp+bjoiNrW22mZmllaZHfx1wIiJejog3gKeB26oviIjvR8TZ8tODwBWtbaaZmS1VmkA/BLxS9fxU+Vg99wLfrnr+G5LGJR2UNJr0Akn3la8ZP336dIommZlZWi2ddSPpbmAEeG/V4SsjoiTpbcABScci4qXq10XEE8ATACMjI0uqsjY2UWLX/uP8bGqaywcH2HLzNYwON/o8MjPrDWkCfQlYU/X8ivKx80i6CfgM8N6IeL1yPCJK5f++LOkHwDDwUu3rl2NsosSWPUeZmZ3/jChNTbNlz1EAB3sz63lpUjeHgKslXSVpJXAncN7sGUnDwOPApoj4RdXxVZIuLj++DLgRqB7EbYnt+yYXgnzFzGywfd9kq/9XZmZdp2mPPiLOSbof2A/0AV+NiElJO4DxiNgL7ALeBHxDEsDJiNgE/AHwuKQ55j9UdtbM1mmJM2dnFnXczKyXpMrRR8RzwHM1xz5b9fimOq/7H8CG5TTQzMyWxytjzcwKLne1bpZi1SX9iWmaVZf0Z9AaM7PFafeswUL06B++dT39fTrvWH+fePjW9Rm1yMwsnbGJElu+cZTS1DRBedbgN44yNnHB5MYlK0SgHx0eYtcd72JocAAx35O/dOVFPLD7CDfuPNDSX5iZWStt2zvJzFzNrMG5YNve1s0aLESgh/lg//zW9/Po5o38amaOqemZhU/HB791zMHezHJpajp5dmC940tRmEBfsWv/caZnZs87Nj0zy679xzNqkZlZtgoX6H82Nb2o42ZmWao3aaSVk0kKF+gvHxxY1HEzsyx1YjJJ4QL9lpuvYaC/77xjA/19bLn5moxaZGZWX+1kkqHBAXbd8a6WTq8sxDz6apVfjitZmlm3GB0eamuMKlygh/b/0szMukkhA30116k3s15X6EDvOvVmZgUcjK3mOvVmZgUP9K5Tb2ZW8EBvZmYFD/SDA8kry+odNzMrokIH+m2b1tO/ombF2QqxbZPLF5tZ7yj0rBsvnjIzK3igBy+eMjMrdOrGzMwc6M3MCq/wqRszsyzloQxLTwb6PPzizaz4xiZKPPitYwu73lW2NoXOlmHpudRN5RdfveO695Q1s3bIy9amPRfo8/KLN7Piy8vWpj0X6PPyizez4svL1qY9F+jz8os3s+J73ztWo5pjWWxt2nOB3nvKmlknjE2U+ObhEtWF0gX8ybs7v4iz52bdVJdFKE1N0yedl6P37Bsza4Wk8cAAvv8/T3e8LT3Xo4f5YF7p2c/Gr3ef8uwbM2uVPI0Hpgr0km6RdFzSCUlbE85/UtKLkn4o6XuSrqw6d4+kH5d/7mll45fDs2/MrJ3yNB7YNNBL6gMeAz4EXAvcJenamssmgJGIeCewB/hi+bVvAR4GrgeuAx6WtKp1zV+6PH3amlnx5Gk8ME2O/jrgRES8DCDpaeA24MXKBRHx/arrDwJ3lx/fDHw3Il4rv/a7wC3AU8tv+vJcPjhAKSGoe/aNmS3HQ2PHeOqFV5iNQIJL+lcwPTOX6Sr8NKmbIeCVquenysfquRf49mJeK+k+SeOSxk+f7sxARdKnLcDZN845T29mS/LQ2DG+fvDkwthfBJydmeOjN6zl+a3vz2yyR0sHYyXdDYwAuxbzuoh4IiJGImJk9erVrWxSXaPDQ3z+9g0XbCt45uwMD+w+wkNjxzrSDjMrjqdeeGVRxzslTaAvAWuqnl9RPnYeSTcBnwE2RcTri3ltVkaHh7j04guzVwE8efCke/ZmtiiVnnza452SJtAfAq6WdJWklcCdwN7qCyQNA48zH+R/UXVqP/BBSavKg7AfLB/LjXqDrwGegWNmqTXqGPapdn1sZzUN9BFxDrif+QD9I+CZiJiUtEPSpvJlu4A3Ad+QdETS3vJrXwM+x/yHxSFgR2VgNi8aDb56Bo6ZpVGpilvPXdevqXuuE1KtjI2I54Dnao59turxTQ1e+1Xgq0ttYLttufkaHth9hKQvVp6BY2ZpJK3Lqbj7hrU8Mrqhwy06X0+ujK02OjzER29Ym4vCQ2bWnep9+xdkHuTBgR6Y/4t4dPNGhgYHELDqkn4uvmgFD+w+wo07D3hQ1swaytMq2CQO9GWjw0M8v/X9PLp5I7+amWNqesY7UJlZKnlaBZvEgb6Ga+CY2WJU9qCenpldmF0zNDjA52/fkJtquD1XprgZ18Axs7RqN/+ejVjoyeclyIN79BfIe67NzPKjWzIADvQ18p5rM7P86JYMgAN9jUoNnMoMnLzl2swsP7olA+AcfYLR4c7v6Whm3WfLzdecl6OHfGYAHOibqIyo/2xqOtN60maWP9V7UOc5RjjQN1A7ol6ZUw/eRNzM5nVDBsA5+gbqjahv2zuZUYvMzBbPgb6BeiPnU9MzXilrZl3Dgb6BRiPneZsna2ZWjwN9A41GzvM2T9bMrB4H+gZGh4dYdUl/4rkVktM3ZtYVHOibePjW9ReslIX5mhauamlm3cCBvonKStmkPR/zWNPCzKyWA30Ko8NDzNXZxd25ejPLOwf6lLqlpoWZWS0H+pRc1dLMupVLIKTULTUtzMxqOdAvQjfUtDAzq+XUjZlZwTnQm5kVnAO9mVnBOUdvZlajaBsOOdCbmVUp4oZDTt2YmVWpt+FQN5c7cY++RYr2Vc+sV9Ura9LN5U7co2+Byle90tQ0wa+/6rmypVn3KWK5Ewf6FijiVz2zXjQ2UeLsG+cuON7t5U5SBXpJt0g6LumEpK0J598j6e8knZN0R825WUlHyj97W9XwPCniVz2zXvPQ2DEe2H2EM2dnzjs+ONDP52/f0NWp2KY5ekl9wGPAB4BTwCFJeyPixarLTgIfAz6d8EdMR8TG5Tc1vy4fHKCUENS7+aueWS8Zmyjx5MGTJBUjv/Tii7o6yEO6Hv11wImIeDki3gCeBm6rviAifhIRPwTm2tDG3HNlS7Putn3fZGKQh2J8M08T6IeAV6qenyofS+s3JI1LOihpNOkCSfeVrxk/ffr0Iv7ofKjsQjU0OICAocGBrv+qZ9YrxiZKF6RrqhXhm3knpldeGRElSW8DDkg6FhEvVV8QEU8ATwCMjIzU+2DNNVe2NOtOjSZNCArxzTxNj74ErKl6fkX5WCoRUSr/92XgB8DwItpnZtZWjVIzH71hbSE6cGkC/SHgaklXSVoJ3Amkmj0jaZWki8uPLwNuBF5s/Cozs84YmyixQko8NzjQzyOjGzrcovZoGugj4hxwP7Af+BHwTERMStohaROApD+UdAr4MPC4pMnyy/8AGJd0FPg+sLNmto6ZWSYqCx1n48Js8UB/H9s2rc+gVe2hSLjJLI2MjMT4+HjWzTCzgtu4/TtMTV84CNsn8aWPvKvrUjaSDkfESNI5r4w1s57z0NixxCAPMBfRdUG+GRc1azMXOzPLl8riqHqKMJ2ylgN9GxWxrrVZt9u1/3jdxVFQjOmUtZy6aSMXOzPLn0bTKVdd0l/ITpgDfRvVe0OVpqZdwtgsI/VSMwIevrU4M22qOdC3UaNcn+vVm2UjqTaVKM7iqCQO9G2U9IaqcArHLBtJtake3byxMIujkngwto0qvYNP7D6SeL4IVfHMulGv1aZyj77NRoeHGCrg1mRm3WZsosSNOw9w1dZnuXHngZ5KnTrQd0C9FM7ZN8711JvNLCu9vq+zA30HVHKCgwP95x0/c3amp95sZlnp9anODvQdMjo8xKUXXzgk0ktvNrMsjE2UErf6hN4ZJ3Og7yBvIm7WWZWUTT29Mk7mQN9B9d5UvfJmM+u0pJRNRS/t6+xA30HeRNyssxp9W+6lfZ0d6DvIm4ibdVa9b8tDgwM99e/OC6Y6rNcWaphloVIevDQ1jeC8apW9+C3agT4HXLPerHVqy4MHLAT7oR799+VAn7GxiRJb9hxlZna+z1GammbLnqOAa9abLUXSAGwlyD+/9f3ZNCpjztFnbPu+yYUgXzEzG2zfN1nnFWbWiKcxX8iBPmNnzibvW1nvuJnVNzZRYoWUeK6XpzE70JtZIVRy87Nx4UaBvTgAW82BPmO19W+aHTezZPUWR/VJPT+N2YE+Y9s2rad/xflfNftXiG2birmlmVk7NKpnMxfR00EePOsmc5U3oKdXmi2N69k050CfA15EZbZ0rmfTnAN9TnkRlVk6rmfTnHP0OdTru+GYLYbr2TTnQJ9Dvb4bjtliuCpsc07d5JBX9pk1V53eHLykn4svWsEvp2ec6kzgQJ9Dlw8OJE4V8+wBs3m1hcvOnJ1hoL+PRzdvdIBPkCp1I+kWScclnZC0NeH8eyT9naRzku6oOXePpB+Xf+5pVcOLzF9FzRpzenNxmvboJfUBjwEfAE4BhyTtjYgXqy47CXwM+HTNa98CPAyMMF9A7nD5tWda0/xi8tx6s8ac3lycNKmb64ATEfEygKSngduAhUAfET8pn5uree3NwHcj4rXy+e8CtwBPLbvlBee59Wb1Ob25OGlSN0PAK1XPT5WPpZHqtZLukzQuafz06dMp/2gz61VOby5OLqZXRsQTETESESOrV6/OujlmlnPef3lx0qRuSsCaqudXlI+lUQL+ec1rf5DytWZmdTm9mV6aHv0h4GpJV0laCdwJ7E355+8HPihplaRVwAfLx8zMrEOaBvqIOAfcz3yA/hHwTERMStohaROApD+UdAr4MPC4pMnya18DPsf8h8UhYEdlYNbMzDpDkbAbS5ZGRkZifHw862aYmXUVSYcjYiTpXC4GY83MrH0c6M3MCs6B3sys4BzozcwKztUrzSxXvLta6znQm1lu1JYfruyuBjjYL4NTN2aWGy4/3B4O9GaWGy4/3B5O3RSM85vWzVx+uD3coy+QsYkSW/YcpTQ1TTCf39yy5yhjE2lr0Jlly+WH28OBvkC275tkZvb8khYzs8H2fZMZtchscVx+uD2cuimQM2dn6h4fmyj5H4t1BZcfbj336HvEg9865hSOWY9yoC+QwYH+uuc8Rc2sdznQF8i2TevpX6G65z1Fzaw3OUdfIJW85qeeOcpswj4DnqJm1pvcoy+Y0eEhvvSRd3mKmpktcI++gCo9ey+cMjNwoC8sT1EzswqnbszMCs49+h7jWjiWBb/vsuVA30Nc69uy4Pdd9py66SGu9W1Z8Psuew70PcS1vi0Lft9lz4G+h9RbMOWFVNZOft9lz4G+h7jWt2XB77vseTC2h3ghlWXB77vsKRJqomRpZGQkxsfHs25Gz/H0N7PuJulwRIwknXOP3hKnvz2w+wjjP32NR0Y3ZNw66xbuLOSXA70lTn8L4OsHTwI42FtTniufbx6MtYbT3L5+8KR3prKmPFc+31IFekm3SDou6YSkrQnnL5a0u3z+BUnrysfXSZqWdKT8859a3H5rgWbT3B781g871BLrVp4rn29NA72kPuAx4EPAtcBdkq6tuexe4ExEvB14FPhC1bmXImJj+efjLWq3tdCWm6+h/r5UMD0z5169NeS58vmWJkd/HXAiIl4GkPQ0cBvwYtU1twHbyo/3AF+W1Ch2WI6MDg8x/tPXFnLySZxvtVoPjR3jqRdeYTYCAX0rxOzcr2fxea58fqRJ3QwBr1Q9P1U+lnhNRJwDfgm8tXzuKkkTkv6bpD9aZnutTZoNuE7PzPKpZ466Z2/AfJD/+sGTC1tWBjA7F1y6sg8BQ4MDfP72De4Y5ES7Z938HFgbEa9KejcwJml9RPyf6osk3QfcB7B27do2N8nqufuGtQ179bMR7tkbAE/WeZ/8amaOf9j5LzrcGmsmTY++BKypen5F+VjiNZIuAt4MvBoRr0fEqwARcRh4Cfj92v9BRDwRESMRMbJ69erF34W1xCOjG7j7hsYftJ5JYWMTJeots0zalN6ylybQHwKulnSVpJXAncDemmv2AveUH98BHIiIkLS6PJiLpLcBVwMvt6bp1g6PjG7gzzdvvKA2STXPpOhtjT7o+zw0l0tNUzcRcU7S/cB+oA/4akRMStoBjEfEXuArwNcknQBeY/7DAOA9wA5JM8Ac8PGIeK0dN2KtU0nLfOqZo4k9NM+k6G2NPujvun5N3XOWnVQ5+oh4Dniu5thnqx7/Cvhwwuu+CXxzmW20DFSCffVqR/BMCpv/oC8lBPtLV/Z5FXVOeWWs1TU6PMTnb9/A0OCAZ1LYgnplh//9v3SQzyvXurGGRoeHHNjtPC473H0c6G3JXK2wd7kD0F0c6G1JXK3QrHs40NuSNKpW6EDf3fxNrXgc6G1JXK2wmPxNrZg868aWxNUKi8l15YvJgd6WpN4Uu/e9YzU37jzAVVuf5cadB1wErcv4m1oxOXVjS5I0xe5971jNNw+X/LW/i9VbDOVvat3Ngd6WrHaK3Y07D3iAtsttufkar4YuIAd6a5l6X+9LU9Os2/osfRJ3Xb/Gy+RzzIuhismB3lqm3tf+itmIhXr3DvbZSDN10ouhiseDsdYySQO0Sb5+8KQHaTMwNlFiy56jlKamCea/aW3Z413DeoEDvbVMbRG0Rj6x+wjDO77jINNB2/dNMjN7ftnpmdlg+77JjFpkneLUjbVU9df+33vwuYY7Dp05O+NZOR1QvYl3kjNnZzrcIus09+itbdJsQuHFOO1Vu4m39Sb36K1tKgOujTYch/lc8VVbn/UMjxaqDLo2GhyvGBzo70CLLEvu0VtbpdmDFlgYHHzwW8ect1+mSr2aNEG+f4XYtml9B1plWXKgt7arDNKm6Tk6lbM8YxMlPvXM0QsWriUZGhxg14ff5W9QPcCpG+uIyiBt9Tzuellj11VZvLGJEtv2TjI1nW5g9e4b1notQw9xoLeOqp6Vc+POA66r0gIPjR3jyYMn635wVvPq5N7kQG+ZaVZXpXpaoANUsrGJUqogP9Df543de5gDvWWmUV2VyrTACpdPSLZr//GmQb5PcpDvcQ70lql6dVWeeuGVxOufeuEVB/oqzcYz3JM3cKC3nKq3wKdXF/7UK0bWqJDcqkv6efjW9Q7y5kBv+dQnJQb1Ps1X0Xlo7BhPvnCSyiWX9K/gP9z+zkIGtUb7uCaNcwj4qGfVWBXPo7dcqlc+4a7r1yzk76s/B87OzPGJ3UfYuL14hdIa7eNaW0huaHCARzdvdJC387hHb7lUCVRJs25+78Hn6r5uarp7C6XVS88028fV9eOtGQd6y61HRjck9kyb5emrV9d2y05JjdIz3sfVlsupG+s6lTx9I5VAWb3JRp7r6DRKzyRt6OJ9XG0x3KO3rnPX9WuaVsTskxID5/Z9k5n18htt49coPeN9XG25FDmbrjYyMhLj4+NZN8NyrnbWTbWB/r5URb1qifkqmkNtCKS1qZlKOytz3OuVgxgaHOD5re9vWTusuCQdjoiRxHNpAr2kW4C/APqAv4yInTXnLwb+Gng38CqwOSJ+Uj73IHAvMAv824jY3+j/5UBvi5XUU05biz2NygdARZ/EDW9bxU9enaY0Nc0KwVzVBUnz15sF8mYfBGbNNAr0TVM3kvqAx4APAKeAQ5L2RsSLVZfdC5yJiLdLuhP4ArBZ0rXAncB64HLgbyT9fkQsvrtlVke9WSe1gXOpartCsxE8/9JrC8/nai44c3aGLXuOLrQNGqdmqq9zesbaIU2O/jrgRES8DCDpaeA2oDrQ3wZsKz/eA3xZksrHn46I14F/kHSi/Of9bWuab5YsKXD+v9fPpS7ju1wzs7Ewzx3SzZzxNElrlzSBfgioLjxyCri+3jURcU7SL4G3lo8frHntBe9kSfcB9wGsXbs2bdvNGqoNnEnpkXaq7sU3q9Rp1k65mF4ZEU9ExEhEjKxevTrr5lhBVa8i7YTa3nrtClbn361T0vToS0D1evQryseSrjkl6SLgzcwPyqZ5rVnHVPfyG83cWa7+Pl3QW3dqxrLSdNZNOXD/PfDHzAfpQ8C/iojJqmv+DNgQER8vD8beHhEfkbQe+M/M5+UvB74HXN1oMNazbixLYxMltu+b5MzZX+fyWzHrxqzdljXrppxzvx/Yz/z0yq9GxKSkHcB4ROwFvgJ8rTzY+hrzM20oX/cM8wO354A/84wbyzP3uq2IvGDKzKwAGvXoczEYa2Zm7eNAb2ZWcA70ZmYF50BvZlZwuRuMlXQa+GnW7Viky4B/zLoRGfB99xbfd75dGRGJK05zF+i7kaTxeqPdReb77i2+7+7l1I2ZWcE50JuZFZwDfWs8kXUDMuL77i2+7y7lHL2ZWcG5R29mVnAO9GZmBedAvwSS3iLpu5J+XP7vqgbX/pakU5K+3Mk2tkOa+5a0UdLfSpqU9ENJm7NoaytIukXScUknJG1NOH+xpN3l8y9IWpdBM1suxX1/UtKL5b/f70m6Mot2tlqz+6667k8khaSumXLpQL80W4HvRcTVzNfYr/umAD4H/PeOtKr90tz3WeBfR8R64BbgzyUNdq6JrSGpD3gM+BBwLXBXebP7avcCZyLi7cCjwBc628rWS3nfE8BIRLyT+T2iv9jZVrZeyvtG0m8C/w54obMtXB4H+qW5Dfir8uO/AkaTLpL0buC3ge90pllt1/S+I+LvI+LH5cc/A34BdOP+kNcBJyLi5Yh4A3ia+fuvVv372AP8sSR1sI3t0PS+I+L7EXG2/PQg8zvHdbs0f98w33H7AvCrTjZuuRzol+a3I+Ln5cf/i/lgfh5JK4AvAZ/uZMParOl9V5N0HbASeKndDWuDhQ3vy5I2tl+4JiLOAb8E3tqR1rVPmvuudi/w7ba2qDOa3rekfwqsiYhnO9mwVkizZ2xPkvQ3wO8knPpM9ZOICElJc1T/FHguIk51UyevBfdd+XN+F/gacE9EzLW2lZYHku4GRoD3Zt2Wdit33P4j8LGMm7IkDvR1RMRN9c5J+t+Sfjcifl4OaL9IuOyfAX8k6U+BNwErJf3fiGiUz89cC+4bSb8FPAt8JiIOtqmp7ZZmY/vKNafKeyu/GXi1M81rmzT3jaSbmP/wf29EvN6htrVTs/v+TeCfAD8od9x+B9graVNE5H5LPKdulmYvcE/58T3Af629ICI+GhFrI2Id8+mbv857kE+h6X1LWgn8F+bvd08H29Zqh4CrJV1Vvqc7mb//atW/jzuAA9H9KxCb3rekYeBxYFNEJH7Yd6GG9x0Rv4yIyyJiXfnf9EHm7z/3QR4c6JdqJ/ABST8Gbio/R9KIpL/MtGXtlea+PwK8B/iYpCPln42ZtHYZyjn3+4H9wI+AZ8qb3e+QtKl82VeAt0o6AXySxrOvukLK+97F/LfUb5T/fms/ALtOyvvuWi6BYGZWcO7Rm5kVnAO9mVnBOdCbmRWcA72ZWcE50JuZFZwDvZlZwTnQm5kV3P8H1qq2dSA837EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# generamos nuestro dataset\n",
    "X, y = generate_real_samples(n=100)\n",
    "# plot samples\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OdbPpUXUZ0gN"
   },
   "source": [
    "Nuestra meta en este caso es ser capaces de generar nuevas parejas de datos $(x, x^2)$ lo más similares posibles a los que generaría la función $f(x)=x^2, x \\in [-0.5, 0.5]$.\n",
    "\n",
    "Vamos a crear primero nuestro discriminador. Lo primero es pensar cuales van a ser las entradas y cuales las salidas. Veamos:\n",
    "\n",
    "Las entradas serán parejas $(x, x^2)$ entre -0.5 y 0.5. Por ejemplo: $(0.2, 0.04)$, $(0.4, 0.16)$, $(-0.2, 0.04)$, $(-0.4, -0.16)$, etc.\n",
    "\n",
    "La salida será un valor binario: 1 si la pareja $(x, x^2)$ realmente se parece a la función $f(x)=x^2$, 0 en caso contrario.\n",
    "\n",
    "Vamos a definirlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8idxYnPYa5_y"
   },
   "outputs": [],
   "source": [
    "# definimos el discriminador\n",
    "def define_discriminator(n_inputs=2):\n",
    "    model = Sequential()\n",
    "    # Nuestro discriminador va a ser muy sencillo: va a tener 2 capas densas.\n",
    "    # la primera, tendrá 25 neuronas, activación relu e inicialización 'he_uniform' (https://keras.io/initializers/)\n",
    "    # además, tendremos que indicarle las dimensiones de entrada (con el atributo input_dim)\n",
    "    model.add(Dense(25, activation='relu', kernel_initializer='he_uniform', input_dim=n_inputs))\n",
    "    # la segunda, será una densa de 1 única neurona y activación sigmoide: \n",
    "    # queremos que nos de la probabilidad de que la imagen sea real\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # utilizamos función de activación final sigmoide y la cross entropía\n",
    "    # binaria para que la red nos devuelva las probabilidades de que la entrada\n",
    "    # sea falsa y real\n",
    "    # el optimizador que usaremos en este caso es el adam con los parámetros por defecto\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Qt1L-2ybrma"
   },
   "source": [
    "Perfecto, ya lo tenemos.\n",
    "\n",
    "Ahora necesitamos el generador. ¿Qué es lo que necesitamos que haga el generador? Que genere 2 números que vamos a intentar aproximar a $(x, x^2)$ mediante entrenamiento.\n",
    "\n",
    "Vamos a ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uuXmHlE7b7kS"
   },
   "outputs": [],
   "source": [
    "# definimos el generador\n",
    "def define_generator(latent_dim, n_outputs=2):\n",
    "    # fijaos en varios detalles:\n",
    "    # - latent_dim: es el tamaño del vector de ruido de la entrada. \n",
    "    # Cuanto mayor sea, más complejos serán los datos que podremos generar\n",
    "    # - la función de activación final ha de ser lineal: esto es muy importante, \n",
    "    # ya que estamos haciendo un trabajo de regresión (estamos tratando de\n",
    "    # llegar a $(x, x^2)$ desde el valor introducido a la red (el vector latente)\n",
    "    # - no compilamos el modelo: esto se debe a que durante el entrenamiento \n",
    "    # del G(z) vamos a necesitar acoplar G(z) a D(x)\n",
    "\n",
    "    # vamos a definir un modelo haciendo uso del modelo Sequential de keras\n",
    "    model = Sequential()\n",
    "    # le añadiremos una capa densa de 15 neuronas, con activación relu e\n",
    "    # inicialización de pesos 'he_uniform', y tendremos que indicarle las \n",
    "    # dimensiones de entrada, igual que en el caso del discriminador\n",
    "    model.add(Dense(15, activation='relu', kernel_initializer='he_uniform', input_dim=latent_dim)) \n",
    "    # la última capa tendrá tantas neuronas como números esperamos generar\n",
    "    # (en este caso x y x^2) y activación lineal\n",
    "    model.add(Dense(n_outputs, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbRHRFr9dEgH"
   },
   "source": [
    "Generador definido. Ahora vamos a combinar el generador y el discriminador para crear el modelo Generativo Adversarial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "wAt6NsGVdMWX"
   },
   "outputs": [],
   "source": [
    "# definimos el modelo GAN combinando generador y discriminador, para entrenar el generador\n",
    "def define_gan(generator, discriminator):\n",
    "    # recordad que durante el entrenamiento del generador necesitamos al\n",
    "    # discriminador para que nos diga si la muestra es real o no, pero\n",
    "    # no debemos actualizar los pesos del discriminador, ya que si no,\n",
    "    # estaríamos haciendo trampas: estaríamos haciendo peor al D(x)\n",
    "    # Así que congelamos el discriminador:\n",
    "    discriminator.trainable = False\n",
    "    # ahora conectamos el G(z) al D(x)\n",
    "    model = Sequential()\n",
    "    # añadimos el generador primero: él es el encargado de generar una muestra\n",
    "    # a partir del espacio latente\n",
    "    model.add(generator)\n",
    "    # y el discriminador después: le introducimos la muestra generada por el \n",
    "    # G(z) para que nos diga si cree que es real o fake\n",
    "    model.add(discriminator)\n",
    "    # y ahora sí, compilamos el modelo con optimizador adam y función de\n",
    "    # pérdidas binary crossentropy\n",
    "    model.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kx9ocDfd2eO"
   },
   "source": [
    "Bueno, ya lo tenemos todo, ¿no?\n",
    "\n",
    "Pues casi, pero no: nos faltan un par de funciones, una que nos devuelva el vector latente que introducirle al G(z) y otra que coja ese vector latente y produzca una muestra fake. \n",
    "\n",
    "Fijaos lo sencillo que es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "q4Rjb3TheBbQ"
   },
   "outputs": [],
   "source": [
    "# generamos los vectores latentes que introduciremos al generador\n",
    "def generate_latent_points(latent_dim, batch_size):\n",
    "    # generamos un vector de batch_size * latent_dim números aleatorios\n",
    "    # latent_dim es la dimensión del vector latente\n",
    "    # batch_size es el número de elementos por batch\n",
    "    x_input = randn(latent_dim * batch_size)\n",
    "    # redimensionamos el vector para que tenga un tamaño (batch_size, latent_dim)\n",
    "    x_input = x_input.reshape(batch_size, latent_dim)\n",
    "    return x_input\n",
    "\n",
    "# creamos datos fake con el generador (dinero falsificado)\n",
    "def generate_fake_samples(generator, latent_dim, n): \n",
    "    # usamos la función anterior para generar los vectores latentes que \n",
    "    # necesitamos para generar muestras fake\n",
    "    # queremos generar 'n' códigos latentes de 'latent_dim'\n",
    "    x_input = generate_latent_points(latent_dim, n)\n",
    "    # le introducimos los vectores latentes al generador para obtener\n",
    "    # muestras similares a las reales\n",
    "    X = generator.predict(x_input)\n",
    "    # le asignamos la etiqueta 0 (porque son falsas)\n",
    "    y = np.zeros((n, 1)) \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIFHKIGWfKks"
   },
   "source": [
    "¡Ahora sí! Ya solo nos falta implementar el bucle de entrenamiento. Vamos a ello:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yx9Fe0AlfOqO"
   },
   "outputs": [],
   "source": [
    "# función para entrenar la GAN: el discriminador y el generador\n",
    "def train(g_model, d_model, gan_model, latent_dim, n_epochs=10000, n_batch=128, n_eval=2000):\n",
    "    # para entrenar el discriminador, le introduciremos la mitad de los datos\n",
    "    # reales y la otra mitad falsa\n",
    "    half_batch = int(n_batch / 2)\n",
    "    for epoch in tqdm(range(n_epochs)):\n",
    "        \n",
    "        # preparamos los datos reales (generados con f(x)=x^2)\n",
    "        x_real, y_real = generate_real_samples(half_batch)\n",
    "        \n",
    "        # preparamos los datos falsos (creados con el generador)\n",
    "        x_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n",
    "        \n",
    "        # entrenamos el discriminador\n",
    "        d_model.train_on_batch(x_real, y_real) # primero con los datos reales\n",
    "        d_model.train_on_batch(x_fake, y_fake) # luego con los datos fake\n",
    "        \n",
    "        # preparamos los puntos en el espacio latente: serán la entrada al\n",
    "        # modelo GAN con el que entrenaremos el generador\n",
    "        x_gan = generate_latent_points(latent_dim, n_batch)\n",
    "        \n",
    "        # creamos etiquetas invertidas para el generador: utilizamos el D(x) \n",
    "        # para que piense que las muestras que le introducimos son reales, y\n",
    "        # en caso de que diga que no son reales, aprovechamos la información\n",
    "        # de sus gradientes para actualizar el G(z) para que la próxima vez\n",
    "        # los datos generados por G(z) sean más plausibles (parecidos a los \n",
    "        # reales)\n",
    "        y_gan = np.ones((n_batch, 1))\n",
    "        \n",
    "        # como acabamos de ver, entrenamos el generador de forma que actualice\n",
    "        # sus pesos usando los gradientes del discriminador\n",
    "        # tened en cuenta que en este modelo (gan_model) el discriminador está\n",
    "        # congelado, por lo que no se actualizan sus pesos: no queremos \"untar\"\n",
    "        # a nuestro policía, lo que queremos es fabricar dinero más realista.\n",
    "        gan_model.train_on_batch(x_gan, y_gan)\n",
    "\n",
    "        # evaluamos el modelo cada n_eval épocas\n",
    "        if (epoch+1) % n_eval == 0 or epoch == 0:\n",
    "            # preparamos ejemplos reales\n",
    "            x_real, y_real = generate_real_samples(n_batch)\n",
    "            # evaluamos el discriminador con datos reales\n",
    "            _, acc_real = discriminator.evaluate(x_real, y_real, verbose=0)\n",
    "            # preparamos ejemplos fake\n",
    "            x_fake, y_fake = generate_fake_samples(generator, latent_dim, n_batch)\n",
    "            # evaluamos el discriminador con datos fake\n",
    "            _, acc_fake = discriminator.evaluate(x_fake, y_fake, verbose=0)\n",
    "            # mostramos cómo de bueno es nuestro policía\n",
    "            print(epoch, acc_real, acc_fake)\n",
    "            # lo ploteamos\n",
    "            plt.scatter(x_real[:, 0], x_real[:, 1], color='red')\n",
    "            plt.scatter(x_fake[:, 0], x_fake[:, 1], color='blue') \n",
    "            # lo guardamos para tenerlo disponible más tarde\n",
    "            filename = 'generated_plot_e%03d.png' % (epoch+1) \n",
    "            plt.savefig(filename)\n",
    "            plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vQ7top0De_tn",
    "outputId": "8cb970b2-8b14-44ba-c74a-aae486ee9797"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                              | 3/10000 [00:01<1:27:49,  1.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.046875 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█████████████▌                                                               | 1761/10000 [01:37<07:11, 19.08it/s]"
     ]
    }
   ],
   "source": [
    "# comenzamos con el entrenamiento\n",
    "\n",
    "# tamaño del espacio latente\n",
    "latent_dim = 5\n",
    "# creamos el discriminador\n",
    "discriminator = define_discriminator()\n",
    "# creamos el generador\n",
    "generator = define_generator(latent_dim)\n",
    "# creamos la GAN\n",
    "gan_model = define_gan(generator, discriminator)\n",
    "# entrenamos!\n",
    "train(generator, discriminator, gan_model, latent_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k-59Xwidifpe"
   },
   "source": [
    "Vamos a ver cómo ha ido el entrenamiento de nuestra red. Para ello, vamos a visualizar la salida del generador al principio, cuando aún no estaba entrenada, y al final, cuando ya estaba entrenada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OxUN_1Jogr1J",
    "outputId": "24c14ade-77e8-4fd8-eb74-b60af2a29a8b"
   },
   "outputs": [],
   "source": [
    "ls -lah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "j0H7eRmCGR01",
    "outputId": "18d528b0-382e-4f08-f09b-1dcd504d92a1"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e001.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "We94v8QvhCPx",
    "outputId": "59dbf006-1a59-4d54-e6c5-94ecc1a01731"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e2000.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "OdSU3tQ_huoX",
    "outputId": "f3ef2ae0-a715-4608-f9ed-79136846502a"
   },
   "outputs": [],
   "source": [
    "plt.imshow(plt.imread('generated_plot_e10000.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JH6r217nkec-"
   },
   "source": [
    "¡Fijáos! El generador ha aprendido a generar datos practicamente iguales a los de nuestro dataset original. ¿Os dáis cuenta de la potencia de esto? Y este es el ejemplo más sencillo que he podido poner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bUqEw6gniDn-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "EDEM - GANs - 1. Mi primera GAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
