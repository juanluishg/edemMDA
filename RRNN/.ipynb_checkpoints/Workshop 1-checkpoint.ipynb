{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZenyhaE7D5U"
   },
   "source": [
    "# Workshop 1: Mobile Price Range Classification\n",
    "\n",
    "In this workshop we will learn how to train a neural network with numeric data as input to predict the price range of mobile phones ([info of the data](https://www.kaggle.com/iabhishekofficial/mobile-price-classification/data#)). The main blocks of the workshop are:\n",
    "\n",
    "1. Get the data from Google Drive.\n",
    "2. Load and Pre-process the data.\n",
    "3. Define a Fully Connected Neural Network.\n",
    "4. Choose loss function and optimizer.\n",
    "5. Train the network.\n",
    "\n",
    "The main libraries thar will be used in the workshop are:\n",
    "\n",
    "- Tensorflow\n",
    "- Keras\n",
    "- Sci-kit Learn\n",
    "- Matplotlib\n",
    "- Numpy\n",
    "- Pandas\n",
    "\n",
    "[Reference](https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ptnsZfN-7A_0"
   },
   "source": [
    "## 1. Get the data from Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yvo1e0KT4zTv"
   },
   "outputs": [],
   "source": [
    "# Import libraries to interact with Google Drive\n",
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qw0YVraI5hjG"
   },
   "outputs": [],
   "source": [
    "# Authenticate with your Google account to get access to the data\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vIJOt1lg5pvG"
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "download = drive.CreateFile({'id': '1igTyUp-YTHG0ig9VeNu83R8jBWn5Djji'})\n",
    "download.GetContentFile('mobile_price.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jRnbuD8c6LLp"
   },
   "outputs": [],
   "source": [
    "# Extract data from zip file\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "data_path = Path(\"./mobile_price.zip\")\n",
    "\n",
    "with zipfile.ZipFile(str(data_path), 'r') as zip_ref:\n",
    "    zip_ref.extractall(\"./data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bxAVc9xw6eHQ"
   },
   "outputs": [],
   "source": [
    "# List files of ./data directory\n",
    "!ls ./data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67CgIbop9ScG"
   },
   "source": [
    "## 2. Load and Pre-process the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DvnZlJFV-21i"
   },
   "outputs": [],
   "source": [
    "# Load dependencies for loading data\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LT55rVd2_IkM"
   },
   "outputs": [],
   "source": [
    "# Load training dataset and check variables\n",
    "dataset = pd.read_csv('./data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2cpgTmCDqzQ"
   },
   "outputs": [],
   "source": [
    "# Show variables\n",
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L2fZ3NwMB0qD"
   },
   "outputs": [],
   "source": [
    "# Show first 5 rows\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GdXq9ybYCAij"
   },
   "outputs": [],
   "source": [
    "# Import dependencies for pre-processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wcNOetOZDZ8B"
   },
   "outputs": [],
   "source": [
    "# Convert pandas Dataframe to Numpy Array\n",
    "dataset_numpy = dataset.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jCSxYok-ByDS"
   },
   "outputs": [],
   "source": [
    "# Show data type before and after conversion\n",
    "print(type(dataset))\n",
    "print(type(dataset_numpy.dtype))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H9H_gM8eHe5O"
   },
   "outputs": [],
   "source": [
    "# Separate input variables from output label\n",
    "X = dataset_numpy[:, :20]\n",
    "y = dataset_numpy[:, 20:21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOciSYTzB8QT"
   },
   "outputs": [],
   "source": [
    "# Show shape of training data and labels\n",
    "print(\"Shape of training data: \", X.shape)\n",
    "print(\"Shape of training labels: \", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu1afk5OIt2c"
   },
   "outputs": [],
   "source": [
    "# Show different classes to predict\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yD9F7PoxIhR7"
   },
   "outputs": [],
   "source": [
    "# Normalizing the data to improve stability while training\n",
    "sc = StandardScaler()\n",
    "sc.fit(X)\n",
    "X_norm = sc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GcYYTbkIHl1p"
   },
   "outputs": [],
   "source": [
    "# Show mean and Standard Deviation learnt from training data\n",
    "print(\"Mean per variable: \\n\", sc.mean_)\n",
    "print(\"Standard Deviation per variable: \\n\", sc.scale_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-PgxBF8oBkYS"
   },
   "outputs": [],
   "source": [
    "# Show data before and after normalization\n",
    "print(\"Before normalization: \\n\", X[1, :])\n",
    "print(\"After normalization: \\n\", X_norm[1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Z_i4ZxzLS5R"
   },
   "outputs": [],
   "source": [
    "# One-hot encoding of labels\n",
    "onehot_enc = OneHotEncoder()\n",
    "y_onehot = onehot_enc.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "suaSrXbWMeZx"
   },
   "outputs": [],
   "source": [
    "# Show labels before and after one-hot encoding\n",
    "print(\"Before onet-hot encodeing: \\n\", y[0])\n",
    "print(\"After onet-hot encodeing: \\n\", y_onehot[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5SbrKQ10Navz"
   },
   "outputs": [],
   "source": [
    "# Split data in training and validation partitions\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_norm, y_onehot, \n",
    "                                                  test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BP1GOQRmOMSK"
   },
   "outputs": [],
   "source": [
    "# Show sizes of partitions\n",
    "print(\"Size of training data: \", X_train.shape)\n",
    "print(\"Size of training labels: \", y_train.shape)\n",
    "print(\"Size of validation data: \", X_val.shape)\n",
    "print(\"Size of validation labels: \", y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M_aOe_XI9Vw7"
   },
   "source": [
    "## 3. Define a Fully Connected Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fdemo-HaPBej"
   },
   "outputs": [],
   "source": [
    "# Import dependencies for designing Keras model\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WW5nXU1YPOtl"
   },
   "outputs": [],
   "source": [
    "# Design simple neural network architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(16, input_dim=20, activation='relu'))\n",
    "model.add(Dense(12, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HRp_OCx8QNXd"
   },
   "outputs": [],
   "source": [
    "# Show model information\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBhIc1LbQfEC"
   },
   "source": [
    "The number of parameters of each layer is obtained as follows:\n",
    "\n",
    "\n",
    "*   params_dense_1 = (input_var_num + 1) * dense_1_neurons = (20 + 1) * 16 = 336\n",
    "*   params_dense_2 = (dense_1_neurons + 1) * dense_2_neurons = (16 + 1) * 12 =      204\n",
    "*   params_dense_3 = (dense_2_neurons + 1) * dense_3_neurons = (12 + 1) * 4 =      52\n",
    "\n",
    "Where +1 comes from the bias term added in each layer.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_pSRNx4w9UKo"
   },
   "source": [
    "## 4. Choose loss function and optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zBF6dr1oSRIC"
   },
   "outputs": [],
   "source": [
    "# Choose loss function, optimizer and training metrics\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CgyWHPSG9wZ1"
   },
   "source": [
    "## 5. Train the network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "97AQk6XZ92pZ"
   },
   "outputs": [],
   "source": [
    "# Choose number of epochs and batch size and train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=64, \n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bCIrA7nQTjV8"
   },
   "outputs": [],
   "source": [
    "# Import dependence for plotting training process \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_5VTbyxsSeOh"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_d47pYo5TUEm"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n",
    "plt.plot(history.history['loss']) \n",
    "plt.plot(history.history['val_loss']) \n",
    "plt.title('Model loss') \n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch') \n",
    "plt.legend(['Train', 'Val'], loc='upper left') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6klS2OaQJwAK"
   },
   "outputs": [],
   "source": [
    "# Save the model\n",
    "from pathlib import Path\n",
    "path = Path('./models')\n",
    "if not path.exists():\n",
    "  path.mkdir()\n",
    "model.save('./models/model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ss_CZ2veKTMl"
   },
   "outputs": [],
   "source": [
    "# List files of ./models directory\n",
    "!ls ./models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-OQ4IRMlU4oB"
   },
   "source": [
    "# Exercise 1: Train the model without normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwK0f6M84pbx"
   },
   "outputs": [],
   "source": [
    "# Split data without normalization in training and validation partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1TNrJWw5XI-"
   },
   "outputs": [],
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ad7wt64u6lYs"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETJDeDTt6tRR"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xvK807CDVCnk"
   },
   "source": [
    "# Exercise 2: Train a simpler model and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zq47RlJJ7E11"
   },
   "outputs": [],
   "source": [
    "# Split data with normalization in training and validation partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dqFSwTf67NY_"
   },
   "outputs": [],
   "source": [
    "# Design a model like the previous but without the second Dense layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Kl6T_sI7nUL"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5rvLhwZ7xJF"
   },
   "outputs": [],
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DepOKe2q8MkJ"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w92LUhf8MVT"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Is_TBOC1VTIE"
   },
   "source": [
    "# Exercise 3: Train a more complex model and evaluate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OjIi9dDDVTrl"
   },
   "outputs": [],
   "source": [
    "# Split data with normalization in training and validation partitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eG_74eNC8r1Z"
   },
   "outputs": [],
   "source": [
    "# Design a model like the previous but with 128 neurons in the first Dense layer\n",
    "# and 256 in the second\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tdqlzys58_9H"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA0FvjzI9ECb"
   },
   "outputs": [],
   "source": [
    "# Train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wVcSFPgD9vvf"
   },
   "outputs": [],
   "source": [
    "# Plot training and validation accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4nmHge409q7k"
   },
   "outputs": [],
   "source": [
    "# Plot training and test loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-a_D8fFqFNJ4"
   },
   "source": [
    "# Exercise 4: Predict the price range of the phones of the test.csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAUk4_kNDfbG"
   },
   "outputs": [],
   "source": [
    "# Read it test data from csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX4h1tgWDyqT"
   },
   "outputs": [],
   "source": [
    "# Show column names (pay attention, maybe there is something different)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oEz2uUWwD3et"
   },
   "outputs": [],
   "source": [
    "# Convert the data to numpy array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ibg8reduGXkT"
   },
   "outputs": [],
   "source": [
    "# Show shape of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ePSNvo6JGcay"
   },
   "outputs": [],
   "source": [
    "# Get rid of a column if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "newYB74PHA05"
   },
   "outputs": [],
   "source": [
    "# Normalize data. Important!! Always normalize test data with the mean and\n",
    "# standard deviation learnt from the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mM2cyGJpJXCP"
   },
   "outputs": [],
   "source": [
    "# Show data before and after normalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e5oBiyCSJoFJ"
   },
   "outputs": [],
   "source": [
    "# Load model saved during the example\n",
    "from keras.models import load_model\n",
    "model = load_model('./models/model_1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QhMVQLxvLMZw"
   },
   "outputs": [],
   "source": [
    "# Predict price range\n",
    "predictions = model.predict(data_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AgYMlxWOLYM_"
   },
   "outputs": [],
   "source": [
    "# Show predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fu017wvWLcgS"
   },
   "outputs": [],
   "source": [
    "# Convert predictions to scalars from one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RC8Vy6RfLn6c"
   },
   "outputs": [],
   "source": [
    "# Show all scalar predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EhlClwb7LvHc"
   },
   "outputs": [],
   "source": [
    "# Show the first test sample in Dataframe format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwFOG4MPMDNj"
   },
   "outputs": [],
   "source": [
    "# Show prediction for that sample\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Workshop 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
