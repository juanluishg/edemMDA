{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jq9d0x1OTh2N"
   },
   "source": [
    "# Prerrequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2_DQBVj_KNvL"
   },
   "source": [
    "Installing Spark and Apache Kafka Library in VM\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xEbGSM3_NM-z"
   },
   "outputs": [],
   "source": [
    "# install Java8\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "# download spark3.0.1\n",
    "!wget -q https://apache.osuosl.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop3.2.tgz\n",
    "\n",
    "# unzip it\n",
    "!tar xf spark-3.0.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark\n",
    "!pip install py4j\n",
    "\n",
    "# For maps\n",
    "!pip install folium\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0qDLAxMTUYQ"
   },
   "source": [
    "Define the environment (Java & Spark homes)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nSd4dfANNndH"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.1-bin-hadoop3.2\"\n",
    "os.environ[\"PYSPARK_SUBMIT_ARGS\"] = \"--master local[*] pyspark-shell\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_IgZEv2XaDm"
   },
   "source": [
    "Starting Spark Session and print the version\n",
    "\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BDLMbVBATf9K"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.0.1'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init(\"c:\\src\\spark-3.0.1-bin-hadoop3.2\")# SPARK_HOME\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# create the session\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.ui.port\", \"4500\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "G28MgeRJHKJ5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-5IEOO84:4501\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x1bb71a732c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "qPrOO29YRuDB"
   },
   "outputs": [],
   "source": [
    "# For Pandas conversion optimization\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNiYuI5dGo8Y"
   },
   "source": [
    "Creating ngrok tunnel to allow Spark UI (Optional)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x4-7fXZiGmqB"
   },
   "outputs": [],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip -o ngrok-stable-linux-amd64.zip\n",
    "!sleep 2\n",
    "get_ipython().system_raw('./ngrok http 4500 &')\n",
    "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
    "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Z0h3dF9Vg4X"
   },
   "source": [
    "# Descargar Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KBDin-0sXgyI"
   },
   "outputs": [],
   "source": [
    "!mkdir -p /dataset\n",
    "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/bank.csv -P /dataset\n",
    "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/vehicles.csv -P /dataset\n",
    "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/characters.csv -P /dataset\n",
    "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/planets.csv -P /dataset\n",
    "!wget -q https://github.com/masfworld/datahack_docker/raw/master/zeppelin/data/species.csv -P /dataset\n",
    "!ls /dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "02Zwm3NRXS_I"
   },
   "source": [
    "# Windows Partitioning\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1o6f6QOjTcZ"
   },
   "source": [
    "## Ejemplo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USrsDETtstv-"
   },
   "outputs": [],
   "source": [
    "!head /dataset/bank.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjPpxRyJYA1h"
   },
   "source": [
    "Leyendo Datos del fichero bank.csv a un Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HnbafeFCVk8d"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "\n",
    "bank_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"sep\", \";\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(\"dataset/bank.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qxhLiwwXk6kD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "|age|          job|marital|education|default|balance|housing|loan| contact|day|month|duration|campaign|pdays|previous|poutcome|  y|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "| 30|   unemployed|married|  primary|     no|   1787|     no|  no|cellular| 19|  oct|      79|       1|   -1|       0| unknown| no|\n",
      "| 33|     services|married|secondary|     no|   4789|    yes| yes|cellular| 11|  may|     220|       1|  339|       4| failure| no|\n",
      "| 35|   management| single| tertiary|     no|   1350|    yes|  no|cellular| 16|  apr|     185|       1|  330|       1| failure| no|\n",
      "| 30|   management|married| tertiary|     no|   1476|    yes| yes| unknown|  3|  jun|     199|       4|   -1|       0| unknown| no|\n",
      "| 59|  blue-collar|married|secondary|     no|      0|    yes|  no| unknown|  5|  may|     226|       1|   -1|       0| unknown| no|\n",
      "| 35|   management| single| tertiary|     no|    747|     no|  no|cellular| 23|  feb|     141|       2|  176|       3| failure| no|\n",
      "| 36|self-employed|married| tertiary|     no|    307|    yes|  no|cellular| 14|  may|     341|       1|  330|       2|   other| no|\n",
      "| 39|   technician|married|secondary|     no|    147|    yes|  no|cellular|  6|  may|     151|       2|   -1|       0| unknown| no|\n",
      "| 41| entrepreneur|married| tertiary|     no|    221|    yes|  no| unknown| 14|  may|      57|       2|   -1|       0| unknown| no|\n",
      "| 43|     services|married|  primary|     no|    -88|    yes| yes|cellular| 17|  apr|     313|       1|  147|       2| failure| no|\n",
      "| 39|     services|married|secondary|     no|   9374|    yes|  no| unknown| 20|  may|     273|       1|   -1|       0| unknown| no|\n",
      "| 43|       admin.|married|secondary|     no|    264|    yes|  no|cellular| 17|  apr|     113|       2|   -1|       0| unknown| no|\n",
      "| 36|   technician|married| tertiary|     no|   1109|     no|  no|cellular| 13|  aug|     328|       2|   -1|       0| unknown| no|\n",
      "| 20|      student| single|secondary|     no|    502|     no|  no|cellular| 30|  apr|     261|       1|   -1|       0| unknown|yes|\n",
      "| 31|  blue-collar|married|secondary|     no|    360|    yes| yes|cellular| 29|  jan|      89|       1|  241|       1| failure| no|\n",
      "| 40|   management|married| tertiary|     no|    194|     no| yes|cellular| 29|  aug|     189|       2|   -1|       0| unknown| no|\n",
      "| 56|   technician|married|secondary|     no|   4073|     no|  no|cellular| 27|  aug|     239|       5|   -1|       0| unknown| no|\n",
      "| 37|       admin.| single| tertiary|     no|   2317|    yes|  no|cellular| 20|  apr|     114|       1|  152|       2| failure| no|\n",
      "| 25|  blue-collar| single|  primary|     no|   -221|    yes|  no| unknown| 23|  may|     250|       1|   -1|       0| unknown| no|\n",
      "| 31|     services|married|secondary|     no|    132|     no|  no|cellular|  7|  jul|     148|       1|  152|       1|   other| no|\n",
      "+---+-------------+-------+---------+-------+-------+-------+----+--------+---+-----+--------+--------+-----+--------+--------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bank_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VHDroSQ1ZQSB"
   },
   "source": [
    "**Obtén el balance de las dos personas más jóvenes por tipo de trabajo**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "3BEWmhhYqxp8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------------+-------+\n",
      "|age|          job|balance|\n",
      "+---+-------------+-------+\n",
      "| 22|       admin.|   4111|\n",
      "| 23|       admin.|      5|\n",
      "| 23|  blue-collar|    817|\n",
      "| 23|  blue-collar|   8627|\n",
      "| 23| entrepreneur|      4|\n",
      "| 25| entrepreneur|  16874|\n",
      "| 26|    housemaid|    543|\n",
      "| 26|    housemaid|   -759|\n",
      "| 23|   management|    736|\n",
      "| 24|   management|    172|\n",
      "| 24|      retired|    366|\n",
      "| 35|      retired|    285|\n",
      "| 25|self-employed|    453|\n",
      "| 26|self-employed|    211|\n",
      "| 21|     services|    361|\n",
      "| 21|     services|   1903|\n",
      "| 19|      student|    103|\n",
      "| 19|      student|      0|\n",
      "| 22|   technician|    333|\n",
      "| 23|   technician|    598|\n",
      "+---+-------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "\n",
    "byJob = Window.partitionBy(\"job\").orderBy(\"age\")\n",
    "\n",
    "bank_df \\\n",
    "  .withColumn(\"new_column_job\", row_number().over(byJob)) \\\n",
    "  .filter(col(\"new_column_job\") <= 2) \\\n",
    "  .select(\"age\", \"job\", \"balance\") \\\n",
    "  .orderBy(\"job\", \"age\") \\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yzU_4EjAjZgh"
   },
   "source": [
    "## Ejercicio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sV-NchsMsHvF"
   },
   "source": [
    "**A partir del Dataframe formado a partir del fichero \"bank.csv\". \n",
    "Obtén el Top 3 de máximos balances por estado civil**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SgireGq6YWEj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+\n",
      "| marital|balance|\n",
      "+--------+-------+\n",
      "|  single|  27733|\n",
      "|  single|  26965|\n",
      "|  single|  25824|\n",
      "| married|  71188|\n",
      "| married|  42045|\n",
      "| married|  27359|\n",
      "|divorced|  26306|\n",
      "|divorced|  13204|\n",
      "|divorced|  10924|\n",
      "+--------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "byJob = Window.partitionBy(\"marital\").orderBy(col(\"balance\").desc())\n",
    "\n",
    "bank_df \\\n",
    "    .withColumn(\"ranking\", row_number().over(byJob)) \\\n",
    "    .filter(col(\"ranking\")<=3) \\\n",
    "    .select(\"marital\", \"balance\") \\\n",
    "    .orderBy(\"marital\",\"balance\", ascending=False) \\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bX0FXU7JawRm"
   },
   "source": [
    "## Ejercicio 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eBtPRPnVmpGM"
   },
   "source": [
    "**Carga el fichero de vehicles.csv en un DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eYPt59chwJUw"
   },
   "outputs": [],
   "source": [
    "!head /dataset/vehicles.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "L6-LoYNzfZFp"
   },
   "outputs": [],
   "source": [
    "vehicles_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"sep\", \";\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(\"dataset/vehicles.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vCDfqm_UxUcn"
   },
   "source": [
    "**Para cada uno de los vehículos, obtén la diferencia de precio (*cost_in_credits*) para cada producto con respecto al más barato en la misma clase de vehículo**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IdhtILfwmSF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GUV9KLzqR-4"
   },
   "source": [
    "# Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tZw41ki6kc3p"
   },
   "source": [
    "## Ejercicio 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAzx5B5IkVeP"
   },
   "source": [
    "**Crea los dataframes correspondientes para los ficheros \"characters.csv\" y \"planets.csv\". <br/>\n",
    "Obtén la gravedad del planeta para cada personaje. Selecciona sólo el nombre del personaje y planeta además de su gravedad**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "WMlJTJzTkC2j"
   },
   "outputs": [],
   "source": [
    "characters_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(\"dataset/characters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "planets_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"sep\", \";\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(\"dataset/planets.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+-----+-------------+----------------+---------+----------+-------------+----------+--------------+\n",
      "|                name|height| mass|   hair_color|      skin_color|eye_color|birth_year|       gender| homeworld|       species|\n",
      "+--------------------+------+-----+-------------+----------------+---------+----------+-------------+----------+--------------+\n",
      "|      Luke Skywalker|   172|   77|        blond|            fair|     blue|     19BBY|         male|  Tatooine|         Human|\n",
      "|               C-3PO|   167|   75|           NA|            gold|   yellow|    112BBY|           NA|  Tatooine|         Droid|\n",
      "|               R2-D2|    96|   32|           NA|     white, blue|      red|     33BBY|           NA|     Naboo|         Droid|\n",
      "|         Darth Vader|   202|  136|         none|           white|   yellow|   41.9BBY|         male|  Tatooine|         Human|\n",
      "|         Leia Organa|   150|   49|        brown|           light|    brown|     19BBY|       female|  Alderaan|         Human|\n",
      "|           Owen Lars|   178|  120|  brown, grey|           light|     blue|     52BBY|         male|  Tatooine|         Human|\n",
      "|  Beru Whitesun lars|   165|   75|        brown|           light|     blue|     47BBY|       female|  Tatooine|         Human|\n",
      "|               R5-D4|    97|   32|           NA|      white, red|      red|        NA|           NA|  Tatooine|         Droid|\n",
      "|   Biggs Darklighter|   183|   84|        black|           light|    brown|     24BBY|         male|  Tatooine|         Human|\n",
      "|      Obi-Wan Kenobi|   182|   77|auburn, white|            fair|blue-gray|     57BBY|         male|   Stewjon|         Human|\n",
      "|    Anakin Skywalker|   188|   84|        blond|            fair|     blue|   41.9BBY|         male|  Tatooine|         Human|\n",
      "|      Wilhuff Tarkin|   180|   NA| auburn, grey|            fair|     blue|     64BBY|         male|    Eriadu|         Human|\n",
      "|           Chewbacca|   228|  112|        brown|              NA|     blue|    200BBY|         male|  Kashyyyk|       Wookiee|\n",
      "|            Han Solo|   180|   80|        brown|            fair|    brown|     29BBY|         male|  Corellia|         Human|\n",
      "|              Greedo|   173|   74|           NA|           green|    black|     44BBY|         male|     Rodia|        Rodian|\n",
      "|Jabba Desilijic T...|   175|1,358|           NA|green-tan, brown|   orange|    600BBY|hermaphrodite| Nal Hutta|          Hutt|\n",
      "|      Wedge Antilles|   170|   77|        brown|            fair|    hazel|     21BBY|         male|  Corellia|         Human|\n",
      "|    Jek Tono Porkins|   180|  110|        brown|            fair|     blue|        NA|         male|Bestine IV|         Human|\n",
      "|                Yoda|    66|   17|        white|           green|    brown|    896BBY|         male|        NA|Yoda's species|\n",
      "|           Palpatine|   170|   75|         grey|            pale|   yellow|     82BBY|         male|     Naboo|         Human|\n",
      "+--------------------+------+-----+-------------+----------------+---------+----------+-------------+----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "characters_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---------------+--------------+--------+--------------------+--------------------+--------------------+-------------+-----------+\n",
      "|          name|rotation_period|orbital_period|diameter|             climate|             gravity|             terrain|surface_water| population|\n",
      "+--------------+---------------+--------------+--------+--------------------+--------------------+--------------------+-------------+-----------+\n",
      "|      Alderaan|             24|           364|   12500|           temperate|          1 standard|grasslands, mount...|           40| 2000000000|\n",
      "|      Yavin IV|             24|          4818|   10200| temperate, tropical|          1 standard| jungle, rainforests|            8|       1000|\n",
      "|          Hoth|             23|           549|    7200|              frozen|        1.1 standard|tundra, ice caves...|          100|         NA|\n",
      "|       Dagobah|             23|           341|    8900|               murky|                 N/A|      swamp, jungles|            8|         NA|\n",
      "|        Bespin|             12|          5110|  118000|           temperate|1.5 (surface), 1 ...|           gas giant|            0|    6000000|\n",
      "|         Endor|             18|           402|    4900|           temperate|       0.85 standard|forests, mountain...|            8|   30000000|\n",
      "|         Naboo|             26|           312|   12120|           temperate|          1 standard|grassy hills, swa...|           12| 4500000000|\n",
      "|     Coruscant|             24|           368|   12240|           temperate|          1 standard|cityscape, mountains|           NA|      1E+12|\n",
      "|        Kamino|             27|           463|   19720|           temperate|          1 standard|               ocean|          100| 1000000000|\n",
      "|      Geonosis|             30|           256|   11370|     temperate, arid|        0.9 standard|rock, desert, mou...|            5|      1E+11|\n",
      "|        Utapau|             27|           351|   12900|temperate, arid, ...|          1 standard|scrublands, savan...|          0.9|   95000000|\n",
      "|      Mustafar|             36|           412|    4200|                 hot|          1 standard|volcanoes, lava r...|            0|      20000|\n",
      "|      Kashyyyk|             26|           381|   12765|            tropical|          1 standard|jungle, forests, ...|           60|   45000000|\n",
      "|   Polis Massa|             24|           590|       0|artificial temper...|       0.56 standard|    airless asteroid|            0|    1000000|\n",
      "|       Mygeeto|             12|           167|   10088|              frigid|          1 standard|glaciers, mountai...|           NA|   19000000|\n",
      "|       Felucia|             34|           231|    9100|          hot, humid|       0.75 standard|      fungus forests|           NA|    8500000|\n",
      "|Cato Neimoidia|             25|           278|       0|    temperate, moist|          1 standard|mountains, fields...|           NA|   10000000|\n",
      "|     Saleucami|             26|           392|   14920|                 hot|                  NA|caves, desert, mo...|           NA| 1400000000|\n",
      "|       Stewjon|             NA|            NA|       0|           temperate|          1 standard|               grass|           NA|         NA|\n",
      "|        Eriadu|             24|           360|   13490|            polluted|          1 standard|           cityscape|           NA|22000000000|\n",
      "+--------------+---------------+--------------+--------+--------------------+--------------------+--------------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "planets_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_pla_df = characters_df.join(planets_df, characters_df.homeworld == planets_df.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-------------+\n",
      "|                name|       name|      gravity|\n",
      "+--------------------+-----------+-------------+\n",
      "|          Wat Tambor|      Skako|            1|\n",
      "|      Wilhuff Tarkin|     Eriadu|   1 standard|\n",
      "|          Tion Medon|     Utapau|   1 standard|\n",
      "|   Poggle the Lesser|   Geonosis| 0.9 standard|\n",
      "|       Ratts Tyerell|Aleen Minor|           NA|\n",
      "|               Dooku|    Serenno|           NA|\n",
      "|            Shaak Ti|      Shili|            1|\n",
      "|           Sly Moore|     Umbara|           NA|\n",
      "|          Mon Mothma|  Chandrila|            1|\n",
      "|           Chewbacca|   Kashyyyk|   1 standard|\n",
      "|             Tarfful|   Kashyyyk|   1 standard|\n",
      "|Wicket Systri War...|      Endor|0.85 standard|\n",
      "|                Yoda|         NA|           NA|\n",
      "|               IG-88|         NA|           NA|\n",
      "|        Arvel Crynyd|         NA|           NA|\n",
      "|        Qui-Gon Jinn|         NA|           NA|\n",
      "|              R4-P17|         NA|           NA|\n",
      "|                Finn|         NA|           NA|\n",
      "|                 Rey|         NA|           NA|\n",
      "|         Poe Dameron|         NA|           NA|\n",
      "+--------------------+-----------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_pla_df.select(characters_df.name, planets_df.name, planets_df.gravity).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HSEBVnVQlU52"
   },
   "source": [
    "## Ejercicio 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JF4fyAaMlXsI"
   },
   "source": [
    "**Revisa el plan de ejecución del ejercicio 3. ¿Qué tipo de join se está ejecutando? ¿Por qué?**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bbYUbaSMlXGc"
   },
   "source": [
    "**Después de revisar el plan de ejecución, ejecuta las siguientes instrucciones**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "y8HYt2Eylh4k"
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "SwEnVoVqnj7D"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.conf.get(\"spark.sql.autoBroadcastJoinThreshold\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxqgghUnlWe3"
   },
   "source": [
    "**Vuelve a ejecutar la consulta del ejercicio 3 que contiene el Join**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+----------+\n",
      "|                name|      name|   gravity|\n",
      "+--------------------+----------+----------+\n",
      "|      Luke Skywalker|  Tatooine|1 standard|\n",
      "|               C-3PO|  Tatooine|1 standard|\n",
      "|               R2-D2|     Naboo|1 standard|\n",
      "|         Darth Vader|  Tatooine|1 standard|\n",
      "|         Leia Organa|  Alderaan|1 standard|\n",
      "|           Owen Lars|  Tatooine|1 standard|\n",
      "|  Beru Whitesun lars|  Tatooine|1 standard|\n",
      "|               R5-D4|  Tatooine|1 standard|\n",
      "|   Biggs Darklighter|  Tatooine|1 standard|\n",
      "|      Obi-Wan Kenobi|   Stewjon|1 standard|\n",
      "|    Anakin Skywalker|  Tatooine|1 standard|\n",
      "|      Wilhuff Tarkin|    Eriadu|1 standard|\n",
      "|           Chewbacca|  Kashyyyk|1 standard|\n",
      "|            Han Solo|  Corellia|1 standard|\n",
      "|              Greedo|     Rodia|1 standard|\n",
      "|Jabba Desilijic T...| Nal Hutta|1 standard|\n",
      "|      Wedge Antilles|  Corellia|1 standard|\n",
      "|    Jek Tono Porkins|Bestine IV|        NA|\n",
      "|                Yoda|        NA|        NA|\n",
      "|           Palpatine|     Naboo|1 standard|\n",
      "+--------------------+----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "char_pla_df = characters_df.join(broadcast(planets_df), characters_df.homeworld == planets_df.name)\n",
    "char_pla_df.select(characters_df.name, planets_df.name, planets_df.gravity).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yT-AFIMvm43z"
   },
   "source": [
    "## Ejercicio 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9UBVU6ym9ue"
   },
   "source": [
    "**Crea un DataFrame a partir del fichero de \"species.csv\" y reparticiona este y el DataFrame de Characters a 100 particiones**\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "ohStdyUGnRC0"
   },
   "outputs": [],
   "source": [
    "species_df = spark.read.format(\"csv\") \\\n",
    "  .option(\"sep\", \",\") \\\n",
    "  .option(\"inferSchema\", \"true\") \\\n",
    "  .option(\"header\", \"true\") \\\n",
    "  .load(\"dataset/species.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+-----------+--------------+--------------------+--------------------+--------------------+----------------+--------------+--------------+\n",
      "|          name|classification|designation|average_height|         skin_colors|         hair_colors|          eye_colors|average_lifespan|      language|     homeworld|\n",
      "+--------------+--------------+-----------+--------------+--------------------+--------------------+--------------------+----------------+--------------+--------------+\n",
      "|          Hutt|     gastropod|   sentient|           300|   green, brown, tan|                  NA|         yellow, red|            1000|       Huttese|     Nal Hutta|\n",
      "|Yoda's species|        mammal|   sentient|            66|       green, yellow|        brown, white|brown, green, yellow|             900|Galactic basic|            NA|\n",
      "|    Trandoshan|       reptile|   sentient|           200|        brown, green|                none|      yellow, orange|              NA|          Dosh|     Trandosha|\n",
      "|  Mon Calamari|     amphibian|   sentient|           160|red, blue, brown,...|                none|              yellow|              NA|Mon Calamarian|      Mon Cala|\n",
      "|          Ewok|        mammal|   sentient|           100|               brown| white, brown, black|       orange, brown|              NA|       Ewokese|         Endor|\n",
      "|     Sullustan|        mammal|   sentient|           180|                pale|                none|               black|              NA|     Sullutese|       Sullust|\n",
      "|     Neimodian|            NA|   sentient|           180|         grey, green|                none|           red, pink|              NA|     Neimoidia|Cato Neimoidia|\n",
      "|        Gungan|     amphibian|   sentient|           190|        brown, green|                none|              orange|              NA|  Gungan basic|         Naboo|\n",
      "|     Toydarian|        mammal|   sentient|           120|   blue, green, grey|                none|              yellow|              91|     Toydarian|      Toydaria|\n",
      "|           Dug|        mammal|   sentient|           100|brown, purple, gr...|                none|        yellow, blue|              NA|        Dugese|     Malastare|\n",
      "|       Twi'lek|       mammals|   sentient|           200|orange, yellow, b...|                none|blue, brown, oran...|              NA|      Twi'leki|        Ryloth|\n",
      "|        Aleena|       reptile|   sentient|            80|          blue, gray|                none|                  NA|              79|        Aleena|   Aleen Minor|\n",
      "|    Vulptereen|            NA|   sentient|           100|                grey|                none|              yellow|              NA|    vulpterish|       Vulpter|\n",
      "|         Xexto|            NA|   sentient|           125|grey, yellow, purple|                none|               black|              NA|       Xextese|       Troiken|\n",
      "|         Toong|            NA|   sentient|           200| grey, green, yellow|                none|              orange|              NA|        Tundan|          Tund|\n",
      "|        Cerean|        mammal|   sentient|           200|           pale pink|red, blond, black...|               hazel|              NA|        Cerean|         Cerea|\n",
      "|      Nautolan|     amphibian|   sentient|           180|green, blue, brow...|                none|               black|              70|       Nautila|   Glee Anselm|\n",
      "|        Zabrak|        mammal|   sentient|           180|pale, brown, red,...|               black|       brown, orange|              NA|       Zabraki|      Iridonia|\n",
      "|    Tholothian|        mammal|   sentient|            NA|                dark|                  NA|        blue, indigo|              NA|            NA|       Tholoth|\n",
      "|      Iktotchi|            NA|   sentient|           180|                pink|                none|              orange|              NA|    Iktotchese|       Iktotch|\n",
      "+--------------+--------------+-----------+--------------+--------------------+--------------------+--------------------+----------------+--------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "species_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_df_repartition = species_df.repartition(100)\n",
    "characters_df_repartition = characters_df.repartition(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tv0AmHi926F7"
   },
   "source": [
    "## Ejercicio 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WR6FPU3b29TP"
   },
   "source": [
    "**Obtén la clasificación de especies para cada personaje. Selecciona sólo el nombre del personaje y su clasificación de especie**<br>\n",
    "Usa los datframes reparticionados\n",
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C0tRj1VIonEX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xG81SgpY4P3t"
   },
   "source": [
    "## Ejercicio 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56fGSsmt4adO"
   },
   "source": [
    "**Ejecuta la siguiente operación sobre el DataFrame del ejercicio 6 y observa la diferencia de reparto de rows entre las particiones**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Io-BtgnHyKZ6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "Jq9d0x1OTh2N",
    "8Z0h3dF9Vg4X",
    "h1o6f6QOjTcZ",
    "tv0AmHi926F7"
   ],
   "name": "02.Spark_SQL_Advanced_Solution.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
